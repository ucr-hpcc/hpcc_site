<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>HPCC â€“ HPC Cluster</title><link>https://hpcc.ucr.edu/manuals/hpc_cluster/</link><description>Recent content in HPC Cluster on HPCC</description><generator>Hugo -- gohugo.io</generator><atom:link href="https://hpcc.ucr.edu/manuals/hpc_cluster/index.xml" rel="self" type="application/rss+xml"/><item><title>Manuals: Introduction</title><link>https://hpcc.ucr.edu/manuals/hpc_cluster/intro/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://hpcc.ucr.edu/manuals/hpc_cluster/intro/</guid><description>
&lt;h2 id="introduction">Introduction&lt;/h2>
&lt;p>This manual provides an introduction to the usage of the HPCC cluster.
All servers and compute resources of the HPCC cluster are available to researchers from all departments and colleges at UC Riverside for a minimal recharge fee &lt;a href="../../about/facility/rates">(see rates)&lt;/a>.
To request an account, please email &lt;a href="mailto:support@hpcc.ucr.edu">support@hpcc.ucr.edu&lt;/a>.
The latest hardware/facility description for grant applications is available &lt;a href="https://goo.gl/43eOwQ">here&lt;/a>.&lt;/p>
&lt;h2 id="overview">Overview&lt;/h2>
&lt;h3 id="storage">Storage&lt;/h3>
&lt;ul>
&lt;li>Four enterprise class HPC storage systems&lt;/li>
&lt;li>Approximately 2 PB (2048 TB) of network storage&lt;/li>
&lt;li>GPFS (NFS and SAMBA via GPFS)&lt;/li>
&lt;li>Automatic snapshots and archival backups&lt;/li>
&lt;/ul>
&lt;h3 id="network">Network&lt;/h3>
&lt;ul>
&lt;li>Ethernet
&lt;ul>
&lt;li>1 Gb/s switch x 5&lt;/li>
&lt;li>1 Gb/s switch 10 Gig uplink&lt;/li>
&lt;li>10 Gb/s switch for Campus wide Science DMZ&lt;/li>
&lt;li>redundant, load balanced, robust mesh topology&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>Interconnect
&lt;ul>
&lt;li>56 Gb/s InfiniBand (FDR)&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;h3 id="head-nodes">Head Nodes&lt;/h3>
&lt;p>All users should access the cluster via ssh through cluster.hpcc.ucr.edu, this address will automatically balance traffic to one of the available head nodes.&lt;/p>
&lt;ul>
&lt;li>Penguin
&lt;ul>
&lt;li>Resources: 8 cores, 64 GB memory&lt;/li>
&lt;li>Primary function: submitting jobs to the queuing system&lt;/li>
&lt;li>Secondary function: development; code editing and running small (under 50 % CPU and under 1 GB RAM) sample jobs&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>Pigeon
&lt;ul>
&lt;li>Resources: 16 cores, 128 GB memory&lt;/li>
&lt;li>Primary function: submitting jobs to the queuing system&lt;/li>
&lt;li>Secondary function: development; code editing and running small (under 50 % CPU and under 1 GB RAM) sample jobs&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>Pelican
&lt;ul>
&lt;li>Resources: 32 cores, 64 GB memory&lt;/li>
&lt;li>Primary function: submitting jobs to the queuing system&lt;/li>
&lt;li>Secondary function: development; code editing and running small (under 50 % CPU and under 1 GB RAM) sample jobs&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>Parrot
&lt;ul>
&lt;li>Resources: 32 cores, 32 GB memory&lt;/li>
&lt;li>Primary function: submitting jobs to the queuing system&lt;/li>
&lt;li>Secondary function: development; code editing and running small (under 50 % CPU and under 1 GB RAM) sample jobs&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;h3 id="worker-nodes">Worker Nodes&lt;/h3>
&lt;ul>
&lt;li>Batch
&lt;ul>
&lt;li>c01-c48: each with 64 AMD cores and 512 GB memory&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>Highmem
&lt;ul>
&lt;li>h01-h06: each with 32 Intel cores and 1024 GB memory&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>GPU
&lt;ul>
&lt;li>gpu01-gpu02: each with 32 (HT) cores Intel Haswell CPUs and 2 x NVIDIA Tesla K80 GPUs (~10000 CUDA cores each) and 128 GB memory&lt;/li>
&lt;li>gpu03-gpu04: each with 32 (HT) cores Intel Haswell CPUs and 4 x NVIDIA Tesla K80 GPUs (~10000 CUDA cores each) and 128 GB memory&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>Intel
&lt;ul>
&lt;li>i01-i40: each with 32 Intel Broadwell cores and 512 GB memory&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul></description></item><item><title>Manuals: Getting Started</title><link>https://hpcc.ucr.edu/manuals/hpc_cluster/start/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://hpcc.ucr.edu/manuals/hpc_cluster/start/</guid><description>
&lt;h2 id="login-from-mac-linux-mobaxterm">Login from Mac, Linux, MobaXTerm&lt;/h2>
&lt;p>The initial login brings users into the cluster head node (i.e. pigeon, pelican, parrot). From there, users can submit jobs via &lt;code>srun&lt;/code>/&lt;code>sbatch&lt;/code> to the compute nodes to perform intensive tests.
Since all machines are mounting a centralized file system, users will always see the same home directory on all systems. Therefore, there is no need to copy files from one machine to another.&lt;/p>
&lt;p>Open the terminal and type&lt;/p>
&lt;pre>&lt;code class="language-bash">ssh -X username@cluster.hpcc.ucr.edu
&lt;/code>&lt;/pre>
&lt;h2 id="login-from-windows">Login from Windows&lt;/h2>
&lt;p>Please refer to the login instructions of our &lt;a href="../../manuals/linux_basics/intro/#windows">Linux Basics manual&lt;/a>.&lt;/p>
&lt;h2 id="change-password">Change Password&lt;/h2>
&lt;ol>
&lt;li>Login via SSH using the Terminal on Mac/Linux or MobaXTerm on Windows&lt;/li>
&lt;/ol>
&lt;ul>
&lt;li>Once you have logged in type the following command:&lt;/li>
&lt;/ul>
&lt;pre>&lt;code>passwd
&lt;/code>&lt;/pre>
&lt;ul>
&lt;li>Enter the old password (the random characters that you were given as your initial password)&lt;/li>
&lt;li>Enter your new password&lt;/li>
&lt;/ul>
&lt;p>The password minimum requirements are:&lt;/p>
&lt;ul>
&lt;li>Total length at least 8 characters long&lt;/li>
&lt;li>Must have at least 3 of the following:
&lt;ul>
&lt;li>Lowercase character&lt;/li>
&lt;li>Uppercase character&lt;/li>
&lt;li>Number&lt;/li>
&lt;li>Punctuation character&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;h2 id="modules">Modules&lt;/h2>
&lt;p>All software used on the HPC cluster is managed through a simple module system.
You must explicitly load and unload each package as needed.
More advanced users may want to load modules within their bashrc, bash_profile, or profile files.&lt;/p>
&lt;h3 id="available-modules">Available Modules&lt;/h3>
&lt;p>To list all available software modules, execute the following:&lt;/p>
&lt;pre>&lt;code class="language-bash">module avail
&lt;/code>&lt;/pre>
&lt;p>This should output something like:&lt;/p>
&lt;pre>&lt;code class="language-bash">------------------------- /usr/local/Modules/versions --------------------------
3.2.9
--------------------- /usr/local/Modules/3.2.9/modulefiles ---------------------
BEDTools/2.15.0(default) modules
PeakSeq/1.1(default) python/3.2.2
SOAP2/2.21(default) samtools/0.1.18(default)
bowtie2/2.0.0-beta5(default) stajichlab
cufflinks/1.3.0(default) subread/1.1.3(default)
matrix2png/1.2.1(default) tophat/1.4.1(default)
module-info
&lt;/code>&lt;/pre>
&lt;h3 id="using-modules">Using Modules&lt;/h3>
&lt;p>To load a module, run:&lt;/p>
&lt;pre>&lt;code class="language-bash">module load &amp;lt;software name&amp;gt;[/&amp;lt;version&amp;gt;]
&lt;/code>&lt;/pre>
&lt;p>For example, to load R version 4.1.2, run:&lt;/p>
&lt;pre>&lt;code class="language-bash">module load R/4.1.2
&lt;/code>&lt;/pre>
&lt;p>To load the default version of the tophat module, run:&lt;/p>
&lt;pre>&lt;code class="language-bash">module load tophat
&lt;/code>&lt;/pre>
&lt;h3 id="show-loaded-modules">Show Loaded Modules&lt;/h3>
&lt;p>To show what modules you have loaded at any time, you can run:&lt;/p>
&lt;pre>&lt;code class="language-bash">module list
&lt;/code>&lt;/pre>
&lt;p>Depending on what modules you have loaded, it will produce something like this:&lt;/p>
&lt;pre>&lt;code class="language-bash">Currently Loaded Modulefiles:
1) vim/7.4.1952 3) slurm/16.05.4 5) R/3.3.0 7) less-highlight/1.0 9) python/3.6.0
2) tmux/2.2 4) openmpi/2.0.1-slurm-16.05.4 6) perl/5.20.2 8) iigb_utilities/1
&lt;/code>&lt;/pre>
&lt;h3 id="unloading-software">Unloading Software&lt;/h3>
&lt;p>Sometimes you want to no longer have a piece of software in path. To do this you unload the module by running:&lt;/p>
&lt;pre>&lt;code class="language-bash">module unload &amp;lt;software name&amp;gt;
&lt;/code>&lt;/pre>
&lt;h2 id="databases">Databases&lt;/h2>
&lt;h3 id="loading-databases">Loading Databases&lt;/h3>
&lt;p>&lt;a href="http://www.ncbi.nlm.nih.gov/">NCBI&lt;/a>, &lt;a href="http://en.wikipedia.org/wiki/Pfam#External_links">PFAM&lt;/a>, and &lt;a href="http://www.uniprot.org/">Uniprot&lt;/a>, do not need to be downloaded by users. They are installed as modules on the cluster.&lt;/p>
&lt;pre>&lt;code>module load db-ncbi
module load db-pfam
module load db-uniprot
&lt;/code>&lt;/pre>
&lt;p>Specific database release numbers can be identified by the version label on the module:&lt;/p>
&lt;pre>&lt;code>module avail db-ncbi
----------------- /usr/local/Modules/3.2.9/modulefiles -----------------
db-ncbi/20140623(default)
&lt;/code>&lt;/pre>
&lt;h3 id="using-databases">Using Databases&lt;/h3>
&lt;p>In order to use the loaded database users can simply provide the corresponding environment variable (NCBI_DB, UNIPROT_DB, PFAM_DB, etc&amp;hellip;) for the proper path in their executables.&lt;/p>
&lt;p>This is the old deprecated BLAST and it may not work in the near future, however if you require it:&lt;/p>
&lt;pre>&lt;code>blastall -p blastp -i proteins.fasta -d $NCBI_DB/nr -o blastp.out
&lt;/code>&lt;/pre>
&lt;p>You can can also use this method if you require the old version of BLAST (old BLAST with legacy support):&lt;/p>
&lt;pre>&lt;code>BLASTBIN=`which legacy_blast.pl | xargs dirname`
legacy_blast.pl blastall -p blastp -i proteins.fasta -d $NCBI_DB/nr -o blast.out --path $BLASTBIN
&lt;/code>&lt;/pre>
&lt;p>This is the preferred/recommended method (BLAST+):&lt;/p>
&lt;pre>&lt;code>blastp -query proteins.fasta -db $NCBI_DB/nr -out proteins_blastp.txt
&lt;/code>&lt;/pre>
&lt;p>Usually, we store the most recent release and 2-3 previous releases of each database. This way time consuming projects can use the same database version throughout their lifetime without always updating to the latest releases.&lt;/p>
&lt;h3 id="additional-features">Additional Features&lt;/h3>
&lt;p>There are additional features and operations that can be done with the module command. Please run the following to get more information:&lt;/p>
&lt;pre>&lt;code class="language-bash">module help
&lt;/code>&lt;/pre>
&lt;h2 id="quotas">Quotas&lt;/h2>
&lt;h3 id="cpu">CPU&lt;/h3>
&lt;p>Currently, the maximum number of CPU cores a user can use simultaneously on the cluster is 256 CPU cores when the load on the cluster is &amp;lt;30% and 128 CPU cores when the load is above 30%. If a user submits jobs for more than 256/128 CPU cores then the additional requests will be queued until resources within the user&amp;rsquo;s CPU quota become available. Upon request a user&amp;rsquo;s upper CPU quota can be extended temporarily, but only if sufficient CPU resources are available. To avoid monopolisation of the cluster by a small number of users, the high load CPU quota of 128 cores is dynamically readjusted by an algorithm that considers the number of CPU hours accumulated by each user over a period of 2 weeks along with the current overall CPU usage on the cluster. If the CPU hour average over the 2 week window exceeds an allowable amount then the default CPU quota will be reduced for such a heavy user to 64 CPU cores, and if it exceeds the allowable amount by two-fold it will be reduced to 32 CPU cores. Once the average usage of a heavy user drops again below those limits, the upper CPU limit will be raised accordingly. Note: when the overall CPU load on the cluster is below 70% then the dynamically readjusted CPU quotas are not applied. At those low load times every user has the same CPU quota: 256 CPU cores at &amp;lt;30% load and 128 CPU cores at 30-70% load.&lt;/p>
&lt;h3 id="data-storage">Data Storage&lt;/h3>
&lt;p>A standard user account has a storage quota of 20GB. Much more storage space, in the range of many TBs, can be made available in a user account&amp;rsquo;s bigdata directory. The amount of storage space available in bigdata depends on a user group&amp;rsquo;s annual subscription. The pricing for extending the storage space in the bigdata directory is available &lt;a href="../../home">here&lt;/a>.&lt;/p>
&lt;h3 id="memory">Memory&lt;/h3>
&lt;p>From the cluster head node users can submit jobs to the batch queue or the highmem queue. The nodes associated with the batch queue are mainly for CPU intensive tasks, while the nodes of the highmem queue are dedicated to memory intensive tasks. The batch nodes allow a 1GB RAM minimum limit on jobs and and the highmem nodes allow 100GB-1024GB RAM jobs.&lt;/p>
&lt;h2 id="whats-next">What&amp;rsquo;s Next?&lt;/h2>
&lt;p>You should now know the following:&lt;/p>
&lt;ol>
&lt;li>Basic orginization of the cluster&lt;/li>
&lt;/ol>
&lt;ul>
&lt;li>How to login to the cluster&lt;/li>
&lt;li>How to use the Module system to gain access to the cluster software&lt;/li>
&lt;li>CPU, storage, and memory limitations (quotas and hardware limits)&lt;/li>
&lt;/ul>
&lt;p>Now you can start using the cluster.&lt;/p>
&lt;p>The HPCC cluster uses the Slurm queuing system and thus the recommended way to run your jobs (scripts, pipelines, experiments, etc&amp;hellip;) is to submit them to this queuing system by using &lt;code>sbatch&lt;/code>.
Please &lt;strong>DO NOT RUN ANY&lt;/strong> computationally intensive tasks on any head node (i.e. pigeon, pelican, parrot). If this policy is violated, your process will either run very slow or be killed.
The head nodes (login nodes) are a shared resource and should be accessible by all users. Negatively impacting performance would affect all users on the system and will not be tolerated.&lt;/p></description></item><item><title>Manuals: Managing Jobs</title><link>https://hpcc.ucr.edu/manuals/hpc_cluster/jobs/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://hpcc.ucr.edu/manuals/hpc_cluster/jobs/</guid><description>
&lt;h2 id="what-is-a-job">What is a Job?&lt;/h2>
&lt;p>Submitting and managing jobs is at the heart of using the cluster. A &amp;lsquo;job&amp;rsquo; refers to the script, pipeline or experiment that you run on the nodes in the cluster.&lt;/p>
&lt;h2 id="partitions">Partitions&lt;/h2>
&lt;p>In the past we used queues under the old Torque system, we now refer to these logically grouped nodes as partitions. There are several different partitions available for cluster users to send jobs to:&lt;/p>
&lt;ul>
&lt;li>intel
&lt;ul>
&lt;li>Default partition&lt;/li>
&lt;li>Nodes: i01-02,i17-i40&lt;/li>
&lt;li>Cores: Intel, 256 per user&lt;/li>
&lt;li>RAM: 1 GB default&lt;/li>
&lt;li>Time (walltime): 168 hours (7 days) default&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>batch
&lt;ul>
&lt;li>Nodes: c01-c48&lt;/li>
&lt;li>Cores: AMD, 256 per user&lt;/li>
&lt;li>RAM: 1 GB default&lt;/li>
&lt;li>Time (walltime): 168 hours (7 days) default&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>highmem
&lt;ul>
&lt;li>Nodes: h01-h06&lt;/li>
&lt;li>Cores: Intel, 32 per user&lt;/li>
&lt;li>RAM: 100 GB min and 1000 GB max&lt;/li>
&lt;li>Time (walltime): 48 hours (2 days) default&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>gpu
&lt;ul>
&lt;li>Nodes: gpu01-gpu05&lt;/li>
&lt;li>GPUs: 8 per group&lt;/li>
&lt;li>RAM: 1 GB default&lt;/li>
&lt;li>Time (walltime): 48 hours (2 days) default&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>short
&lt;ul>
&lt;li>Nodes: Mixed set of nodes from batch, intel, and group partitions&lt;/li>
&lt;li>Cores: AMD/Intel, 256 per user&lt;/li>
&lt;li>RAM: 1 GB default&lt;/li>
&lt;li>Time (walltime): 2 hours Maximum&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>Group Partition
&lt;ul>
&lt;li>This partition is unique to the group, if your lab has purchased nodes then you will have a priority partition with the same name as your group (ie. girkelab).
In order to submit a job to different partitions add the optional &amp;lsquo;-p&amp;rsquo; parameter with the name of the partition you want to use:&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;pre>&lt;code class="language-bash">sbatch -p batch SBATCH_SCRIPT.sh
sbatch -p highmem SBATCH_SCRIPT.sh
sbatch -p gpu SBATCH_SCRIPT.sh
sbatch -p intel SBATCH_SCRIPT.sh
sbatch -p mygroup SBATCH_SCRIPT.sh
&lt;/code>&lt;/pre>
&lt;h2 id="slurm">Slurm&lt;/h2>
&lt;p>Slurm is now our default queuing system across all head nodes. &lt;a href="#getting-started">SSH directly into the cluster&lt;/a> and your connection will be automatically load balanced to a head node:&lt;/p>
&lt;pre>&lt;code class="language-bash">ssh -XY cluster.hpcc.ucr.edu
&lt;/code>&lt;/pre>
&lt;h3 id="resources-and-limits">Resources and Limits&lt;/h3>
&lt;p>To see your limits you can do the following:&lt;/p>
&lt;pre>&lt;code class="language-bash">slurm_limits
&lt;/code>&lt;/pre>
&lt;p>Check total number of cores used by your group in the all partitions:&lt;/p>
&lt;pre>&lt;code class="language-bash">group_cpus
&lt;/code>&lt;/pre>
&lt;p>However this does not tell you when your job will start, since it depends on the duration of each job.
The best way to do this is with the &amp;ldquo;&amp;ndash;start&amp;rdquo; flag on the squeue command:&lt;/p>
&lt;pre>&lt;code class="language-bash">squeue --start -u $USER
&lt;/code>&lt;/pre>
&lt;h3 id="submitting-jobs">Submitting Jobs&lt;/h3>
&lt;p>There are 2 basic ways to submit jobs; non-interactive, interactive. Slurm will automatically start within the directory where you submitted the job from, so keep that in mind when you use relative file paths.
Non-interactive submission of a SBATCH script:&lt;/p>
&lt;pre>&lt;code class="language-bash">sbatch SBATCH_SCRIPT.sh
&lt;/code>&lt;/pre>
&lt;p>Here is an example of an SBATCH script:&lt;/p>
&lt;pre>&lt;code class="language-bash">#!/bin/bash -l
#SBATCH --nodes=1
#SBATCH --ntasks=1
#SBATCH --cpus-per-task=10
#SBATCH --mem=10G
#SBATCH --time=1-00:15:00 # 1 day and 15 minutes
#SBATCH --mail-user=useremail@address.com
#SBATCH --mail-type=ALL
#SBATCH --job-name=&amp;quot;just_a_test&amp;quot;
#SBATCH -p intel # This is the default partition, you can use any of the following; intel, batch, highmem, gpu
# Print current date
date
# Load samtools
module load samtools
# Concatenate BAMs
samtools cat -h header.sam -o out.bam in1.bam in2.bam
# Print name of node
hostname
&lt;/code>&lt;/pre>
&lt;p>The above job will request 1 node, 10 cores (parallel threads), 10GB of memory, for 1 day and 15 minutes. An email will be sent to the user when the status of the job changes (Start, Failed, Completed).
For more information regarding parallel/multi core jobs refer to &lt;a href="#parallelization">Parallelization&lt;/a>.&lt;/p>
&lt;p>Interactive submission:&lt;/p>
&lt;pre>&lt;code class="language-bash">srun --pty bash -l
&lt;/code>&lt;/pre>
&lt;p>If you do not specify a partition then the intel partition is used by default.&lt;/p>
&lt;p>Here is a more complete example:&lt;/p>
&lt;pre>&lt;code class="language-bash">srun --mem=1gb --cpus-per-task 1 --ntasks 1 --time 10:00:00 --pty bash -l
&lt;/code>&lt;/pre>
&lt;p>The above example enables X11 forwarding and requests, 1GB of memory, 1 cores, for 10 hours within an interactive session.&lt;/p>
&lt;h3 id="monitoring-jobs">Monitoring Jobs&lt;/h3>
&lt;p>To check on your jobs states, run the following:&lt;/p>
&lt;pre>&lt;code class="language-bash">squeue -u $USER --start
&lt;/code>&lt;/pre>
&lt;p>To list all the details of a specific job, run the following:&lt;/p>
&lt;pre>&lt;code class="language-bash">scontrol show job JOBID
&lt;/code>&lt;/pre>
&lt;p>To view past jobs and their details, run the following:&lt;/p>
&lt;pre>&lt;code class="language-bash">sacct -u $USER -l
&lt;/code>&lt;/pre>
&lt;p>You can also adjust the start &lt;code>-S&lt;/code> time and/or end &lt;code>-E&lt;/code> time to view, using the YYYY-MM-DD format.
For example, the following command uses start and end times:&lt;/p>
&lt;pre>&lt;code class="language-bash">sacct -u $USER -S 2018-01-01 -E 2018-08-30 -l | less -S # Type 'q' to quit
&lt;/code>&lt;/pre>
&lt;h3 id="canceling-jobs">Canceling Jobs&lt;/h3>
&lt;p>In cancel/stop your job run the following:&lt;/p>
&lt;pre>&lt;code class="language-bash">scancel &amp;lt;JOBID&amp;gt;
&lt;/code>&lt;/pre>
&lt;p>You can also cancel multiple jobs:&lt;/p>
&lt;pre>&lt;code class="language-bash">scancel &amp;lt;JOBID1&amp;gt; &amp;lt;JOBID2&amp;gt; &amp;lt;JOBID3&amp;gt;
&lt;/code>&lt;/pre>
&lt;p>If you want to cancel/stop/kill ALL your jobs it is possible with the following:&lt;/p>
&lt;pre>&lt;code class="language-bash"># Be very careful when running this, it will kill all your jobs.
squeue --user $USER --noheader --format '%i' | xargs scancel
&lt;/code>&lt;/pre>
&lt;p>For more information please refer to &lt;a href="https://slurm.schedmd.com/scancel.html" title="Slurm scancel doc">Slurm scancel documentation&lt;/a>.&lt;/p>
&lt;h3 id="advanced-jobs">Advanced Jobs&lt;/h3>
&lt;p>There is a third way of submitting jobs by using steps.
Single Step submission:&lt;/p>
&lt;pre>&lt;code class="language-bash">srun &amp;lt;command&amp;gt;
&lt;/code>&lt;/pre>
&lt;p>Under a single step job your command will hang until appropriate resources are found and when the step command is finished the results will be sent back on STDOUT. This may take some time depending on the job load of the cluster.
Multi Step submission:&lt;/p>
&lt;pre>&lt;code class="language-bash">salloc -N 4 bash -l
srun &amp;lt;command&amp;gt;
...
srun &amp;lt;command&amp;gt;
exit
&lt;/code>&lt;/pre>
&lt;p>Under a multi step job the salloc command will request resources and then your parent shell will be running on the head node. This means that all commands will be executed on the head node unless preceeded by the srun command. You will also need to exit this shell in order to terminate your job.&lt;/p>
&lt;h3 id="highmem-jobs">Highmem Jobs&lt;/h3>
&lt;p>The highmem partition does not have a default amount of memory set, however it does has a minimum limit of 100GB per job. This means that you need to explicity request at least 100GB or more of memory.&lt;/p>
&lt;p>Non-Interactive:&lt;/p>
&lt;pre>&lt;code class="language-bash">sbatch -p highmem --mem=100g --time=24:00:00 SBATCH_SCRIPT.sh
&lt;/code>&lt;/pre>
&lt;p>Interactive&lt;/p>
&lt;pre>&lt;code class="language-bash">srun -p highmem --mem=100g --time=24:00:00 --pty bash -l
&lt;/code>&lt;/pre>
&lt;p>Of course you should adjust the time argument according to your job requirements.&lt;/p>
&lt;h3 id="gpu-jobs">GPU Jobs&lt;/h3>
&lt;p>GPU nodes have multiple GPUs, and very in type (K80 or P100). This means you need to request how many GPUs and of what type that you would like to use.&lt;/p>
&lt;p>To request a gpu of any type, only indicate how many GPUs you would like to use.&lt;/p>
&lt;p>Non-Interactive:&lt;/p>
&lt;pre>&lt;code class="language-bash">sbatch -p gpu --gres=gpu:1 --mem=100g --time=1:00:00 SBATCH_SCRIPT.sh
&lt;/code>&lt;/pre>
&lt;p>Interactive&lt;/p>
&lt;pre>&lt;code class="language-bash">srun -p gpu --gres=gpu:4 --mem=100g --time=1:00:00 --pty bash -l
&lt;/code>&lt;/pre>
&lt;p>Since the HPCC Cluster has two types of GPUs installed (K80s and P100s), GPUs can be requested explicitly by type.&lt;/p>
&lt;p>Non-Interactive:&lt;/p>
&lt;pre>&lt;code class="language-bash">sbatch -p gpu --gres=gpu:k80:1 --mem=100g --time=1:00:00 SBATCH_SCRIPT.sh
sbatch -p gpu --gres=gpu:p100:1 --mem=100g --time=1:00:00 SBATCH_SCRIPT.sh
&lt;/code>&lt;/pre>
&lt;p>Interactive&lt;/p>
&lt;pre>&lt;code class="language-bash">srun -p gpu --gres=gpu:k80:1 --mem=100g --time=1:00:00 --pty bash -l
srun -p gpu --gres=gpu:p100:1 --mem=100g --time=1:00:00 --pty bash -l
&lt;/code>&lt;/pre>
&lt;p>Of course you should adjust the time argument according to your job requirements.&lt;/p>
&lt;p>Once your job starts your code must reference the environment variable &amp;ldquo;CUDA_VISIBLE_DEVICES&amp;rdquo; which will indicate which GPUs have been assigned to your job. Most CUDA enabled software, like MegaHIT, will check this environment variable and automatically limit accordingly.&lt;/p>
&lt;p>For example, when reserving 4 GPUs for a NAMD2 job:&lt;/p>
&lt;pre>&lt;code class="language-bash">echo $CUDA_VISIBLE_DEVICES
0,1,2,3
namd2 +idlepoll +devices $CUDA_VISIBLE_DEVICES MD1.namd
&lt;/code>&lt;/pre>
&lt;p>Each group is limited to a maximum of 8 GPUs on the gpu partition. Please be respectful of others and keep in mind that the GPU nodes are a limited shared resource.
Since the CUDA libraries will only run with GPU hardward, development and compiling of code must be done within a job session on a GPU node.&lt;/p>
&lt;p>Here are a few more examples of jobs that utilize more complex features (ie. array, dependency, MPI etc):
&lt;a href="https://github.com/ucr-hpcc/hpcc_slurm_examples">Slurm Examples&lt;/a>&lt;/p>
&lt;h3 id="web-browser-access">Web Browser Access&lt;/h3>
&lt;h4 id="ports">Ports&lt;/h4>
&lt;p>Some jobs require web browser access in order to utilize the software effectively.
These kinds of jobs typically use (bind) ports in order to provide a graphical user interface (GUI) through a web browser.
Users are able to run jobs that use (bind) ports on a compute node.
Any port can be used on any compute node, as long as the port number is greater than 1000 and it is not already in use (bound).&lt;/p>
&lt;h4 id="tunneling">Tunneling&lt;/h4>
&lt;p>Once a job is running on a compute node and bound to a port, you may access this compute node via a web browser.
This is accomplished by using 2 chained SSH tunnels to route traffic through our firewall.
This acts much like 2 runners in a relay race, handing the baton to the next runer, to get past a security checkpoint.&lt;/p>
&lt;p>We will create a tunnel that goes though a headnode and connect to a compute node on a particular port:&lt;/p>
&lt;pre>&lt;code class="language-bash">ssh -NL 8888:NodeName:8888 username@cluster.hpcc.ucr.edu
&lt;/code>&lt;/pre>
&lt;p>Port 8888 (first) is the local port you will be using on your laptop.
NodeName is the compute node where where job is running, which can be found by using the &lt;code>squeue -u $USER&lt;/code> command.
Port 8888 (second) is the remote port on the compute node.
Again, the NodeName and ports will be different depending on where your job runs and what port your job uses.&lt;/p>
&lt;p>At this point you may need to provide a password to make the SSH tunnel.
Once this has succeeded, the command will hang (this is normal).
Leave this session connected, if you close it your tunnel will be closed.&lt;/p>
&lt;p>Then open a browser on your local computer (PC/laptop) and point it to:&lt;/p>
&lt;pre>&lt;code>http://localhost:8888
&lt;/code>&lt;/pre>
&lt;p>If your job uses TSL/SSL, so you may need to try https if the above does not work:&lt;/p>
&lt;pre>&lt;code>https://localhost:8888
&lt;/code>&lt;/pre>
&lt;h4 id="examples">Examples&lt;/h4>
&lt;ol>
&lt;li>
&lt;p>A perfect example of this method is used for Jupyter Lab/Notebook. For more details please refer to the following &lt;a href="https://github.com/ucr-hpcc/hpcc_slurm_examples/tree/master/jupyter">Jupyter Example&lt;/a>.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>RStudio Server instances can also be started directly on a compute node and accessed via an SSH tunnel. For details see &lt;a href="https://hpcc.ucr.edu/manuals/linux_basics/text/#2-compute-node-instance">here&lt;/a>.&lt;/p>
&lt;/li>
&lt;/ol>
&lt;h3 id="desktop-environments">Desktop Environments&lt;/h3>
&lt;h4 id="vnc-server-cluster">VNC Server (cluster)&lt;/h4>
&lt;p>&lt;strong>Start VNC Server&lt;/strong>&lt;/p>
&lt;p>Log into the cluster:&lt;/p>
&lt;pre>&lt;code class="language-bash">ssh username@cluster.hpcc.ucr.edu
&lt;/code>&lt;/pre>
&lt;p>The first time you run the vncserver it will need to be configured:&lt;/p>
&lt;pre>&lt;code class="language-bash">vncserver -fg
&lt;/code>&lt;/pre>
&lt;p>You should set a password for yourself, and the read-only password is optional.&lt;/p>
&lt;p>Then configure X Startup with the following command:&lt;/p>
&lt;pre>&lt;code class="language-bash">echo '/usr/bin/ssh-agent /usr/bin/dbus-launch --exit-with-session /usr/bin/gnome-session --session=gnome-classic' &amp;gt; /rhome/$USER/.vnc/xstartup
&lt;/code>&lt;/pre>
&lt;p>After your vncserver is configured, submit a vncserver job to get it started:&lt;/p>
&lt;pre>&lt;code class="language-bash">sbatch -p short,batch --cpus-per-task=4 --mem=10g --time=2:00:00 --wrap='vncserver -fg' --output='vncserver-%j.out'
&lt;/code>&lt;/pre>
&lt;blockquote>
&lt;p>Note: Appropriate job resources should be requested based on the processes you will be running from within the VNC session.&lt;/p>
&lt;/blockquote>
&lt;p>Check the contents of your job log to determine the &lt;code>NodeName&lt;/code> and &lt;code>Port&lt;/code> you were assigned:&lt;/p>
&lt;pre>&lt;code class="language-bash">cat vncserver-*.out
&lt;/code>&lt;/pre>
&lt;p>The contents of your slurm job log should be similar to the following:&lt;/p>
&lt;pre>&lt;code class="language-bash">vncserver
New 'i54:1' desktop is i54:1
Creating default startup script /rhome/username/.vnc/xstartup
Starting applications specified in /rhome/username/.vnc/xstartup
Log file is /rhome/username/.vnc/i54:1.log
&lt;/code>&lt;/pre>
&lt;p>The VNC &lt;code>Port&lt;/code> used should be 5900+N, N being the display number mentioned above in the format &lt;code>NodeName&lt;/code>:&lt;code>DisplayNumber&lt;/code> (ie. &lt;code>i54:1&lt;/code>).
In this example (default), the port is &lt;code>5901&lt;/code>, if this &lt;code>Port&lt;/code> were already in use then the vncserver will automatically increment the DisplayNumber and you might find something like &lt;code>i54:2&lt;/code> or &lt;code>i54:3&lt;/code> and so on.&lt;/p>
&lt;p>&lt;strong>Stop VNC Server&lt;/strong>&lt;/p>
&lt;p>To stop the vncserver, you can click on the logout option from the upper right hand menu from within your VNC desktop environment.
If you want to kill your vncserver manually, then you will need to do the following:&lt;/p>
&lt;pre>&lt;code class="language-bash">ssh NodeName 'vncserver -kill :DisplayNumber'
&lt;/code>&lt;/pre>
&lt;p>You will need to replace &lt;code>NodeName&lt;/code> with the node name of your where your job is running, and the &lt;code>DisplayNumber&lt;/code> with the DisplayNumber from your slurm job log.&lt;/p>
&lt;h4 id="vnc-client-desktoplaptop">VNC Client (Desktop/Laptop)&lt;/h4>
&lt;p>After you know the &lt;code>NodeName&lt;/code> and VNC &lt;code>Port&lt;/code> you should be able to create an SSH tunnel to your vncserver, like so:&lt;/p>
&lt;pre>&lt;code class="language-bash">ssh -N -L Port:NodeName:Port cluster.hpcc.ucr.edu
&lt;/code>&lt;/pre>
&lt;p>Now let us create an SSH tunnel on your local machine (desktop/laptop) using the &lt;code>NodeName&lt;/code> and VNC &lt;code>Port&lt;/code> from above:&lt;/p>
&lt;pre>&lt;code class="language-bash">ssh -L 5901:i54:5901 cluster.hpcc.ucr.edu
&lt;/code>&lt;/pre>
&lt;p>After you have logged into the cluster with this shell, log into the node where your VNC server is running:&lt;/p>
&lt;pre>&lt;code class="language-bash">ssh NodeName
&lt;/code>&lt;/pre>
&lt;p>After you have logged into the correct &lt;code>NodeName&lt;/code>, just let this terminal sit here, do not close it.&lt;/p>
&lt;p>Then launch vncviewer on your local system (laptop/workstation), like so:&lt;/p>
&lt;pre>&lt;code class="language-bash">vncviewer localhost:5901
&lt;/code>&lt;/pre>
&lt;p>After launching the vncviewer, and providing your VNC password (not your cluster password), you should be able to see a Linux desktop environment.&lt;/p>
&lt;p>For more information regarding tunnels and VNC in MS Windows, please refer &lt;a href="https://docs.ycrc.yale.edu/clusters-at-yale/access/vnc/">More VNC Info&lt;/a>.&lt;/p>
&lt;h3 id="licenses">Licenses&lt;/h3>
&lt;p>The cluster currently supports &lt;a href="../../about/software/commercial/">Commercial Software&lt;/a>. Since most of the licenses are campus wide there is no need to track individual jobs. One exception is the Intel Parallel Suite, which contains the Intel compilers.&lt;/p>
&lt;p>The &lt;code>--licenses&lt;/code> flag is used to request a license for Intel compilers, for example:&lt;/p>
&lt;pre>&lt;code class="language-bash">srun --license=intel:1 -p short --mem=10g --cpus-per-task=10 --time=2:00:00 --pty bash -l
module load intel
icc -help
&lt;/code>&lt;/pre>
&lt;p>The above interactive submission will request 1 Intel license, 10GB of RAM, 10 CPU cores for 2 hours on the short partition.
The short parititon can only be used for a maximum of 2 hours, however for compilation this could be sufficient.
It is recommended that you separate your compilation job from your computation/analysis job.
This way you will only have the license checked out for the duration of compilation, and not the during the execution of the analysis.&lt;/p>
&lt;h2 id="parallelization">Parallelization&lt;/h2>
&lt;p>There are 3 major ways to parallelize work on the cluster:&lt;/p>
&lt;ol>
&lt;li>Batch&lt;/li>
&lt;li>Thread&lt;/li>
&lt;li>MPI&lt;/li>
&lt;/ol>
&lt;h3 id="parallel-methods">Parallel Methods&lt;/h3>
&lt;p>For &lt;strong>batch&lt;/strong> jobs, all that is required is that you have a way to split up the data and submit multiple jobs running with the different chunks.
Some data sets, for example a FASTA file is very easy to split up (ie. fasta-splitter). This can also be more easily achieved by submitting an array job. For more details please refer to &lt;a href="#advanced-jobs">Advanced Jobs&lt;/a>.&lt;/p>
&lt;p>For &lt;strong>threaded&lt;/strong> jobs, your software must have an option referring to &amp;ldquo;number of threads&amp;rdquo; or &amp;ldquo;number of processors&amp;rdquo;. Once the thread/processor option is identified in the software, (ie. blastn flag &lt;code>-num_threads 4&lt;/code>) you can use that as long as you also request the same number of CPU cores (ie. slurm flag &lt;code>--cpus-per-task=4&lt;/code>).&lt;/p>
&lt;p>For &lt;strong>MPI&lt;/strong> jobs, your software must be MPI enabled. This generally means that it was compiled with MPI libraries. Please refer to the user manual of the software you wish to use as well as our documentation regarding &lt;a href="#mpi">MPI&lt;/a>. It is important that the number of cores used is equal to the number requested.&lt;/p>
&lt;p>In Slurm you will need 2 different flags to request cores, which may seem similar, however they have different purposes:&lt;/p>
&lt;ul>
&lt;li>The &lt;code>--cpus-per-task=N&lt;/code> will provide N number of virtual cores with locality as a factor.
Closer virtual cores can be faster, assuming there is a need for rapid communication between threads.
Generally, this is good for threading, however not so good for independent subprocesses nor for MPI.&lt;/li>
&lt;li>The &lt;code>--ntasks=N&lt;/code> flag will provide N number of physical cores on a single or even multiple nodes.
These cores can be further away, since the need for physical CPUs and dedicated memory is more important.
Generally this is good for independent subprocesses, and MPI, however not so good for threading.&lt;/li>
&lt;/ul>
&lt;p>Here is a table to better explain when to use these Slurm options:&lt;/p>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th>Slurm Flag&lt;/th>
&lt;th>Single Threaded&lt;/th>
&lt;th>Multi Threaded (OpenMP)&lt;/th>
&lt;th>MPI only&lt;/th>
&lt;th>MPI + Multi Threaded (hybrid)&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>&lt;code>--cpus-per-task&lt;/code>&lt;/td>
&lt;td>&lt;/td>
&lt;td>X&lt;/td>
&lt;td>&lt;/td>
&lt;td>X&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;code>--ntasks&lt;/code>&lt;/td>
&lt;td>&lt;/td>
&lt;td>&lt;/td>
&lt;td>X&lt;/td>
&lt;td>X&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;p>As you can see:&lt;/p>
&lt;ol>
&lt;li>A single threaded job would use neither Slurm option, since Slurm already assumes at least a single core.&lt;/li>
&lt;li>A multi threaded OpenMP job would use &lt;code>--cpus-per-task&lt;/code>.&lt;/li>
&lt;li>A MPI job would use &lt;code>--ntasks&lt;/code>.&lt;/li>
&lt;li>A Hybrid job would use both.&lt;/li>
&lt;/ol>
&lt;p>For more details on how these Slurm options work please review &lt;a href="https://slurm.schedmd.com/mc_support.html">Slurm Multi-core/Multi-thread Support&lt;/a>.&lt;/p>
&lt;h4 id="mpi">MPI&lt;/h4>
&lt;p>MPI stands for the Message Passing Interface. MPI is a standardized API typically used for parallel and/or distributed computing.
The HPCC cluster has a custom compiled versions of MPI that allows users to run MPI jobs across multiple nodes.
These types of jobs have the ability to take advantage of hundreds of CPU cores symultaniously, thus improving compute time.&lt;/p>
&lt;p>Many implementations of MPI exists, however we only support the following:&lt;/p>
&lt;ul>
&lt;li>&lt;a href="http://www.open-mpi.org/">Open MPI&lt;/a>&lt;/li>
&lt;li>&lt;a href="http://www.mpich.org/">MPICH&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://software.intel.com/en-us/mpi-developer-guide-linux">IMPI&lt;/a>&lt;/li>
&lt;/ul>
&lt;p>For general information on MPI under Slurm look &lt;a href="https://slurm.schedmd.com/mpi_guide.html">here&lt;/a>.
If you need to compile an MPI application then please email &lt;a href="mailto:support@hpcc.ucr.edu">support@hpcc.ucr.edu&lt;/a> for assistance.&lt;/p>
&lt;p>When submitting MPI jobs it is best to ensure that the nodes are identical, since MPI is sensitive to differences in CPU and/or memory speeds.
The &lt;code>batch&lt;/code> and &lt;code>intel&lt;/code> partitions are designed to be homogeneous, however, the &lt;code>short&lt;/code> partition is a mixed set of nodes.
When using the &lt;code>short&lt;/code> partition for MPI append the constraint flag for Slurm.&lt;/p>
&lt;p>&lt;strong>Short Example&lt;/strong>&lt;/p>
&lt;p>Here is an example that shows how to ensure that your job will only run on &lt;code>intel&lt;/code> nodes from the &lt;code>short&lt;/code> partition:&lt;/p>
&lt;pre>&lt;code class="language-bash">sbatch -p short --constraint=intel myJobScript.sh
&lt;/code>&lt;/pre>
&lt;p>&lt;strong>NAMD Example&lt;/strong>&lt;/p>
&lt;p>To run a NAMD2 process as an OpenMPI job on the cluster:&lt;/p>
&lt;ol>
&lt;li>
&lt;p>Log-in to the cluster&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Create SBATCH script&lt;/p>
&lt;pre>&lt;code class="language-bash">#!/bin/bash -l
#SBATCH -J c3d_cr2_md
#SBATCH -p batch
#SBATCH --ntasks=32
#SBATCH --mem=16gb
#SBATCH --time=01:00:00
# Load needed modules
# You could also load frequently used modules from within your ~/.bashrc
module load slurm # Should already be loaded
module load openmpi # Should already be loaded
module load namd
# Run job utilizing all requested processors
# Please visit the namd site for usage details: http://www.ks.uiuc.edu/Research/namd/
mpirun --mca btl ^tcp namd2 run.conf &amp;amp;&amp;gt; run_namd.log
&lt;/code>&lt;/pre>
&lt;/li>
&lt;li>
&lt;p>Submit SBATCH script to Slurm queuing system&lt;/p>
&lt;pre>&lt;code class="language-bash">sbatch run_namd.sh
&lt;/code>&lt;/pre>
&lt;/li>
&lt;/ol>
&lt;p>&lt;strong>Maker Example&lt;/strong>&lt;/p>
&lt;p>OpenMPI does not function properly with Maker, you must use MPICH.
Our version of MPICH does not use the mpirun/mpiexec wrappers, instead use srun:&lt;/p>
&lt;pre>&lt;code class="language-bash">#!/bin/bash -l
#SBATCH -p intel
#SBATCH --ntasks=32
#SBATCH --mem=16gb
#SBATCH --time=01:00:00
# Load maker
module load maker/2.31.11
mpirun maker # Provide appropriate maker options here
&lt;/code>&lt;/pre>
&lt;h2 id="more-examples">More examples&lt;/h2>
&lt;p>The range of differing jobs and how to submit them is endless:&lt;/p>
&lt;pre>&lt;code>1. Singularity containers
2. Database services
3. Graphical user interfaces
4. Etc ...
&lt;/code>&lt;/pre>
&lt;p>For a growing list of examples please visit &lt;a href="https://github.com/ucr-hpcc/hpcc_slurm_examples">HPCC Slurm Examples&lt;/a>.&lt;/p></description></item><item><title>Manuals: Queue Policies</title><link>https://hpcc.ucr.edu/manuals/hpc_cluster/queue/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://hpcc.ucr.edu/manuals/hpc_cluster/queue/</guid><description>
&lt;h2 id="start-times">Start Times&lt;/h2>
&lt;p>Start times are a great way to track your jobs:&lt;/p>
&lt;pre>&lt;code class="language-bash">squeue -u $USER --start
&lt;/code>&lt;/pre>
&lt;p>Start times are rough estimates based on the current state of the queue.&lt;/p>
&lt;h2 id="fair-share">Fair-Share&lt;/h2>
&lt;p>Users that have not submitted any jobs in a long time usually have a higher priority over others that have ran jobs recently.
Thus the estimated start times can be extended to allow everyone their fair share of the system.
This prevents a few large groups from dominating the queuing system for long periods of time.&lt;/p>
&lt;p>You can see with the &lt;code>sqmore&lt;/code> command what priority your job has (list is sorted from lowest to highest priority).
You can also check to see how your group&amp;rsquo;s priority is compared to other groups on the cluster with the &amp;ldquo;sshare&amp;rdquo; command.&lt;/p>
&lt;p>For example:&lt;/p>
&lt;pre>&lt;code class="language-bash">sshare
&lt;/code>&lt;/pre>
&lt;p>It may also be useful to see your entire group&amp;rsquo;s fairshare score and who has used the most shares:&lt;/p>
&lt;pre>&lt;code class="language-bash">sshare -A $GROUP --all
&lt;/code>&lt;/pre>
&lt;p>Lastley, if you only want to see your own fairshare score:&lt;/p>
&lt;pre>&lt;code class="language-bash">sshare -A $GROUP -u $USER
&lt;/code>&lt;/pre>
&lt;p>The fairshare score is a number between 0 and 1. The best score being 1, and the worst being 0.
The fairshare score approches zero the more resource you (or your group) consume.
Your individual consumption of resources (usage) does affect your entire group&amp;rsquo;s fiarshare score.
The affects of your running/completed jobs on your fairshare score are halved each day (half-life).
Thus, after waiting several days without running any jobs, you should see an improvment in your fairshare score.&lt;/p>
&lt;p>Here is a very good &lt;a href="https://www.rc.fas.harvard.edu/fairshare/">explaination of fairshare&lt;/a>.&lt;/p>
&lt;h2 id="priority">Priority&lt;/h2>
&lt;p>The fairshare score and jobs queue wait time is used to calculate your job&amp;rsquo;s priority.
You can use the &lt;code>sprio&lt;/code> command to check the priority of your jobs:&lt;/p>
&lt;pre>&lt;code>sprio -u $USER
&lt;/code>&lt;/pre>
&lt;p>Even if your group has a lower fairshare score, your job may still have a very high priority.
This would be likely due to the job&amp;rsquo;s queue wait time, and it should start as soon as possible regardless of fairshare score.
You can use the &lt;code>sqmore&lt;/code> command to see a list of all jobs sorted by priority.&lt;/p>
&lt;h2 id="backfill">Backfill&lt;/h2>
&lt;p>Some small jobs may start before yours, only if they can complete before yours starts and thus not negatively affecting your start time.&lt;/p>
&lt;h2 id="priority-partition">Priority Partition&lt;/h2>
&lt;p>Some groups on our system have purchased additional hardware. These nodes will not be affected by the fairshare score.
This is because jobs submitted to the group&amp;rsquo;s partition will be evaluated first before any other jobs that have been submitted to those nodes from a different partition.&lt;/p></description></item><item><title>Manuals: Package Management</title><link>https://hpcc.ucr.edu/manuals/hpc_cluster/package_manage/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://hpcc.ucr.edu/manuals/hpc_cluster/package_manage/</guid><description>
&lt;h2 id="python">Python&lt;/h2>
&lt;p>The scope of this manual is a brief introduction on how to manage Python packages.&lt;/p>
&lt;h3 id="python-versions">Python Versions&lt;/h3>
&lt;p>Different Python versions do not play nice with each other. It is best to only load one Python module at any given time.
The miniconda2 module for Python is the default version. This will enable users to leverage the conda installer, but with as few Python packages pre-installed as possible. This is to avoid conflicts with future needs of individuals.&lt;/p>
&lt;h4 id="conda">Conda&lt;/h4>
&lt;p>We have several Conda software modules:&lt;/p>
&lt;ol>
&lt;li>miniconda2 - Basic Python 2 install (default)&lt;/li>
&lt;li>miniconda3 - Basic Python 3 install&lt;/li>
&lt;li>anaconda2 - Full Python 2 install&lt;/li>
&lt;li>anaconda3 - Full Python 3 install
For more information regarding our module system please refer to &lt;a href="../../manuals/hpc_cluster/start/#modules">Environment Modules&lt;/a>.&lt;/li>
&lt;/ol>
&lt;p>The miniconda modules are very basic installs, however users can choose to unload this basic install for a fuller one (anaconda), like so:&lt;/p>
&lt;pre>&lt;code class="language-bash">module load miniconda2 #This is the default
&lt;/code>&lt;/pre>
&lt;p>After loading anaconda, you will see that there are many more Python packages installed (ie. numpy, scipy, pandas, jupyter, etc&amp;hellip;).
For a list of installed Python packages try the following:&lt;/p>
&lt;pre>&lt;code class="language-bash">pip list
&lt;/code>&lt;/pre>
&lt;h4 id="virtual-environments">Virtual Environments&lt;/h4>
&lt;p>Sometimes it is best to create your own environment in which you have full control over package installs.
Conda allows you to do this through virtual environments.&lt;/p>
&lt;h5 id="initialize">Initialize&lt;/h5>
&lt;p>Conda will now auto initialize when you load the corresponding module. No need to run the &lt;code>conda init&lt;/code> or make any modifications to your &lt;code>~/.bashrc&lt;/code> file.&lt;/p>
&lt;h5 id="configure">Configure&lt;/h5>
&lt;p>Installing many packages can consume a large (ie. &amp;gt;20GB) amount of disk space, thus it is recommended to store conda environments under your bigdata space.
If you have bigdata, create the &lt;code>.condarc&lt;/code> file (otherwise conda environments will be created under your home directory).&lt;/p>
&lt;p>Create the file &lt;code>.condarc&lt;/code> in your home, with the following content:&lt;/p>
&lt;pre>&lt;code>channels:
- defaults
pkgs_dirs:
- ~/bigdata/.conda/pkgs
envs_dirs:
- ~/bigdata/.conda/envs
auto_activate_base: false
&lt;/code>&lt;/pre>
&lt;p>Then create your Python 2 conda environment, like so:&lt;/p>
&lt;pre>&lt;code class="language-bash">conda create -n NameForNewEnv python=2.7.14 # Many Python versions are available
&lt;/code>&lt;/pre>
&lt;p>For Python 3, please use the miniconda3, like so:&lt;/p>
&lt;pre>&lt;code class="language-bash">module unload miniconda2
module load miniconda3
conda create -n NameForNewEnv python=3.6.4 # Many Python versions are available
&lt;/code>&lt;/pre>
&lt;h5 id="activating">Activating&lt;/h5>
&lt;p>Once your virtual environment has been created, you need to activate it before you can use it:&lt;/p>
&lt;pre>&lt;code class="language-bash">conda activate NameForNewEnv
&lt;/code>&lt;/pre>
&lt;h5 id="deactivating">Deactivating&lt;/h5>
&lt;p>In order to exit from your virtual environment, do the following:&lt;/p>
&lt;pre>&lt;code class="language-bash">conda deactivate
&lt;/code>&lt;/pre>
&lt;h5 id="installing-packages">Installing packages&lt;/h5>
&lt;p>Before installing your packages, make sure you are on a computer node. This ensures your downloads to be done quickly and with less chance of running out of memory. This can be done using the following command:&lt;/p>
&lt;pre>&lt;code class="language-bash">srun -p short -c 4 --mem=10g --pty bash -l # Adjust the resource request as needed
&lt;/code>&lt;/pre>
&lt;p>Here is a simple example for installing packages under your Python virtual environment via conda:&lt;/p>
&lt;pre>&lt;code class="language-bash">conda install -n NameForNewEnv PackageName
&lt;/code>&lt;/pre>
&lt;p>You may need to enable an additional channel to install the package (refer to your package&amp;rsquo;s documentation):&lt;/p>
&lt;pre>&lt;code class="language-bash">conda install -n NameForNewEnv -c ChannelName PackageName
&lt;/code>&lt;/pre>
&lt;h5 id="cloning">Cloning&lt;/h5>
&lt;p>It is possible for you to copy an existing environment into a new environment:&lt;/p>
&lt;pre>&lt;code class="language-bash">conda create --name AnotherNameForNewEnv --clone NameForNewEnv
&lt;/code>&lt;/pre>
&lt;h5 id="listing-environments">Listing Environments&lt;/h5>
&lt;p>Run the following to get a list of currently installed conda evironments:&lt;/p>
&lt;pre>&lt;code class="language-bash">conda env list
&lt;/code>&lt;/pre>
&lt;h5 id="removing">Removing&lt;/h5>
&lt;p>If you wish to remove a conda environment run the following:&lt;/p>
&lt;pre>&lt;code class="language-bash">conda env remove --name myenv
&lt;/code>&lt;/pre>
&lt;h4 id="more-info">More Info&lt;/h4>
&lt;p>For more information regarding conda please visit &lt;a href="https://conda.io/docs/user-guide/">Conda Docs&lt;/a>.&lt;/p>
&lt;h3 id="jupyter">Jupyter&lt;/h3>
&lt;p>You can run jupyter as an interactive job using &lt;a href="../../hpc_cluster/jobs/#web-browser-access">tunneling&lt;/a>, or you can use the web portal &lt;a href="https://jupyter.hpcc.ucr.edu">Jupyter-Hub&lt;/a>.&lt;/p>
&lt;h4 id="virtual-environment">Virtual Environment&lt;/h4>
&lt;p>In order to enable your conda virtual environemnt within the Jupyter web portal you will need to do the following:&lt;/p>
&lt;pre>&lt;code class="language-bash"># Create a virtual environment, if you don't already have one
conda create -n ipykernel_py2 python=2 ipykernel
# Load the new environment
conda activate ipykernel_py2
# Install kernel
python -m ipykernel install --user --name myenv --display-name &amp;quot;JupyterPy2&amp;quot;
&lt;/code>&lt;/pre>
&lt;p>Now when you visit &lt;a href="https://jupyter.hpcc.ucr.edu">Jupyter-Hub&lt;/a> you should see the option &amp;ldquo;JupyterPy2&amp;rdquo; when you click the &amp;ldquo;New&amp;rdquo; dropdown menu in the upper left corner of the home page.&lt;/p>
&lt;h4 id="r">R&lt;/h4>
&lt;p>For instructions on how to configure your R environment please visit &lt;a href="https://github.com/IRkernel/IRkernel">IRkernel&lt;/a>.
Since we should already have IRkernel install in the latest version of R, you would only need to do the following within R:&lt;/p>
&lt;pre>&lt;code class="language-R">IRkernel::installspec(name = 'ir44', displayname = 'R 4.0.1')
&lt;/code>&lt;/pre>
&lt;h2 id="r-1">R&lt;/h2>
&lt;p>This section is regarding how to manage R packages.&lt;/p>
&lt;h3 id="current-r-version">Current R Version&lt;/h3>
&lt;blockquote>
&lt;p>NOTE: Please be aware that this version of R is built with &lt;code>GCC/8.3.0&lt;/code>, which means that previously compiled modules may be incompatible.&lt;/p>
&lt;/blockquote>
&lt;p>Currently the default version of R is &lt;code>R/4.1.0&lt;/code> and is &lt;code>NOT&lt;/code> loaded automatically for you.&lt;/p>
&lt;p>You will have to do this manually on your own, like so:&lt;/p>
&lt;pre>&lt;code class="language-bash">module load R/4.1.0_gcc-8.3.0
&lt;/code>&lt;/pre>
&lt;p>Or, you can &lt;code>rebase&lt;/code> by loading the &lt;code>base/gcc/8.3.0&lt;/code> module, which will load the latest version of &lt;code>R&lt;/code> and many other compatible modules:&lt;/p>
&lt;pre>&lt;code class="language-bash">module load base/gcc/8.3.0
&lt;/code>&lt;/pre>
&lt;p>If you wish to revert back to your previous modules, then you can simply unload the &lt;code>base&lt;/code> module, like so:&lt;/p>
&lt;pre>&lt;code>module unload base
&lt;/code>&lt;/pre>
&lt;p>When a new release of R is available, you should reinstall any local R packages, however keep in mind of the following:&lt;/p>
&lt;ul>
&lt;li>Remove redundantly installed local R packages with the &lt;code>RdupCheck&lt;/code> command.&lt;/li>
&lt;li>Newer version of R packages are not backward compatible, once installed they only work for that specific version of &lt;code>R&lt;/code>.&lt;/li>
&lt;/ul>
&lt;h3 id="older-r-versions">Older R Versions&lt;/h3>
&lt;p>The older version of &lt;code>R/4.0.1&lt;/code> is loaded by default.&lt;/p>
&lt;p>You can load other versions of R with the following:&lt;/p>
&lt;pre>&lt;code class="language-bash">module unload R
module load R/3.4.2
&lt;/code>&lt;/pre>
&lt;h3 id="installing-r-packages">Installing R Packages&lt;/h3>
&lt;p>The default version of &lt;code>R&lt;/code> has many of the most popular &lt;code>R&lt;/code> packages already installed and available.
It is also possible for you to install additional R packages in your local environment.&lt;/p>
&lt;p>Only install packages if they are not already available, this will minimize issues later.
You can check the current version of &lt;code>R&lt;/code> from the command line, like so:&lt;/p>
&lt;pre>&lt;code class="language-bash">Rscript -e &amp;quot;library('some-package-name')&amp;quot;
&lt;/code>&lt;/pre>
&lt;p>Or you can check from within &lt;code>R&lt;/code>, like so:&lt;/p>
&lt;pre>&lt;code class="language-R">library('some-package-name')
&lt;/code>&lt;/pre>
&lt;p>If the package is not available, then proceed with installation.&lt;/p>
&lt;h4 id="bioconductor-packages">Bioconductor Packages&lt;/h4>
&lt;p>To install from Bioconductor you can use the following method:&lt;/p>
&lt;pre>&lt;code class="language-R">BiocManager::install(c(&amp;quot;package-to-install&amp;quot;, &amp;quot;another-packages-to-install&amp;quot;))
Update all/some/none? [a/s/n]: n
&lt;/code>&lt;/pre>
&lt;p>For more information please visit &lt;a href="https://www.bioconductor.org/install/">Bioconductor Install Page&lt;/a>.&lt;/p>
&lt;h4 id="github-packages">GitHub Packages&lt;/h4>
&lt;pre>&lt;code class="language-R"># Load devtools
library(devtools)
# Replace name with the GitHub account/repo
install_github(&amp;quot;duncantl/RGoogleDocs&amp;quot;)
&lt;/code>&lt;/pre>
&lt;h4 id="local-packages">Local Packages&lt;/h4>
&lt;pre>&lt;code class="language-R"># Replace URL with your URL or local path to your .tar.gz file
install.packages(&amp;quot;http://hartleys.github.io/QoRTs/QoRTs_LATEST.tar.gz&amp;quot;,repos=NULL,type=&amp;quot;source&amp;quot;)
&lt;/code>&lt;/pre></description></item><item><title>Manuals: Data Storage</title><link>https://hpcc.ucr.edu/manuals/hpc_cluster/storage/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://hpcc.ucr.edu/manuals/hpc_cluster/storage/</guid><description>
&lt;h2 id="dashboard">Dashboard&lt;/h2>
&lt;p>HPCC cluster users are able to check on their home and bigdata storage usage from the &lt;a href="https://dashboard.hpcc.ucr.edu">Dashboard Portal&lt;/a>.&lt;/p>
&lt;h2 id="home">Home&lt;/h2>
&lt;p>Home directories are where you start each session on the HPC cluster and where your jobs start when running on the cluster. This is usually where you place the scripts and various things you are working on. This space is very limited. Please remember that the home storage space quota per user account is 20 GB.&lt;/p>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th>Path&lt;/th>
&lt;th>/rhome/&lt;code>username&lt;/code>&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>User Availability&lt;/td>
&lt;td>All Users&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>Node Availability&lt;/td>
&lt;td>All Nodes&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>Quota Responsibility&lt;/td>
&lt;td>User&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;h2 id="bigdata">Bigdata&lt;/h2>
&lt;p>Bigdata is an area where large amounts of storage can be made available to users. A lab purchases bigdata space separately from access to the cluster. This space is then made available to the lab via a shared directory and individual directories for each user.&lt;/p>
&lt;p>&lt;strong>Lab Shared Space&lt;/strong>
This directory can be accessed by the lab as a whole.&lt;/p>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th>Path&lt;/th>
&lt;th>/bigdata/&lt;code>labname&lt;/code>/shared&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>User Availability&lt;/td>
&lt;td>Labs that have purchased space.&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>Node Availability&lt;/td>
&lt;td>All Nodes&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>Quota Responsibility&lt;/td>
&lt;td>Lab&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;p>&lt;strong>Individual User Space&lt;/strong>
This directory can be accessed by specific lab members.&lt;/p>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th>Path&lt;/th>
&lt;th>/bigdata/&lt;code>labname&lt;/code>/&lt;code>username&lt;/code>&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>User Availability&lt;/td>
&lt;td>Labs that have purchased space.&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>Node Availability&lt;/td>
&lt;td>All Nodes&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>Quota Responsibility&lt;/td>
&lt;td>Lab&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;h2 id="non-persistent-space">Non-Persistent Space&lt;/h2>
&lt;p>Frequently, there is a need for faster temporary storage. For example activities like the following would fall under this category:
1. Output a significant amount of intermediate data during a job
2. Access a dataset from a faster medium than bigdata or the home directories
3. Write out lock files&lt;/p>
&lt;p>These types of activities are well suited to the use of fast non-persistent spaces. Below are the filesystems available on the HPC cluster that would best suited for these actions.&lt;/p>
&lt;p>&lt;strong>Temporary Space&lt;/strong>
This is a standard space available on all Linux systems. Please be aware that it is limited to the amount of free disk space on the node you are running on.&lt;/p>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th>Path&lt;/th>
&lt;th>/tmp&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>User Availability&lt;/td>
&lt;td>All Users&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>Node Availability&lt;/td>
&lt;td>All Nodes&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>Quota Responsibility&lt;/td>
&lt;td>N/A&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;p>&lt;strong>SSD Backed Space&lt;/strong>
This space is much faster than the persistent space (/rhome,/bigdata), but slower than using RAM based storage.&lt;/p>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th>Path&lt;/th>
&lt;th>/scratch&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>User Availability&lt;/td>
&lt;td>All Users&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>Node Availability&lt;/td>
&lt;td>All Nodes&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>Quota Responsibility&lt;/td>
&lt;td>N/A&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;p>&lt;strong>RAM Space&lt;/strong>
This type of space takes away from physical memory but allows extremely fast access to the files located on it. When submitting a job you will need to factor in the space your job is using in RAM as well. For example, if you have a dataset that is 1G in size and use this space, it will take at least 1G of RAM.&lt;/p>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th>Path&lt;/th>
&lt;th>/dev/shm&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>User Availability&lt;/td>
&lt;td>All Users&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>Node Availability&lt;/td>
&lt;td>All Nodes&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>Quota Responsibility&lt;/td>
&lt;td>N/A&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;h2 id="usage-and-quotas">Usage and Quotas&lt;/h2>
&lt;p>To quickly check your usage and quota limits:&lt;/p>
&lt;pre>&lt;code class="language-bash">check_quota home
check_quota bigdata
&lt;/code>&lt;/pre>
&lt;p>To get the usage of your current directory, run the following command:&lt;/p>
&lt;pre>&lt;code class="language-bash">du -sh .
&lt;/code>&lt;/pre>
&lt;p>To calculate the sizes of each separate sub directory, run:&lt;/p>
&lt;pre>&lt;code class="language-bash">du -shc *
&lt;/code>&lt;/pre>
&lt;p>This may take some time to complete, please be patient.&lt;/p>
&lt;p>For more information on your home directory, please see the &lt;a href="../../manuals/linux_basics/cmdline_basics/">Linux Basics Orientation&lt;/a>.&lt;/p>
&lt;h2 id="automatic-backups">Automatic Backups&lt;/h2>
&lt;p>The cluster does create backups however it is still advantageous for users to periodically make copies of their critical data to a separate storage device.
The cluster is a production system for research computations with a very expensive high-performance storage infrastructure. It is not a data archiving system.&lt;/p>
&lt;p>Home backups are created daily and kept for one week.
Bigdata backups are created weekly and kept for one month.&lt;/p>
&lt;p>Home and bigdata backups are located under the following respective directories:&lt;/p>
&lt;pre>&lt;code class="language-bash">/rhome/.snapshots/
/bigdata/.snapshots/
&lt;/code>&lt;/pre>
&lt;p>The individual snapshot directories have names with numerical values in epoch time format.
The higher the value the more recent the snapshot.&lt;/p>
&lt;p>To view the exact time of when each snapshot was taken execute the following commands:&lt;/p>
&lt;pre>&lt;code class="language-bash">mmlssnapshot home
mmlssnapshot bigdata
&lt;/code>&lt;/pre></description></item><item><title>Manuals: Sharing Data</title><link>https://hpcc.ucr.edu/manuals/hpc_cluster/sharing/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://hpcc.ucr.edu/manuals/hpc_cluster/sharing/</guid><description>
&lt;h2 id="permissions">Permissions&lt;/h2>
&lt;p>It is useful to share data and results with other users on the cluster, and we
encourage collaboration. The easiest way to share a file is to place it in a
location that both users can access. Then the second user can simply copy it to
a location of their choice. However, this requires that the file permissions
permit the second user to read the file. Basic file permissions on Linux and
other Unix like systems are composed of three groups: owner, group, and other.
Each one of these represents the permissions for different groups of people:
the user who owns the file, all the group members of the group owner, and
everyone else, respectively Each group has 3 permissions: read, write, and
execute, represented as r,w, and x. For example the following file is owned by
the user &lt;code>username&lt;/code> (with read, write, and execute), owned by the group
&lt;code>groupname&lt;/code> (with read and execute), and everyone else cannot access it.&lt;/p>
&lt;pre>&lt;code class="language-bash">username@pigeon:~$ ls -l myFile
-rwxr-x--- 1 username groupname 1.6K Nov 19 12:32 myFile
&lt;/code>&lt;/pre>
&lt;p>If you wanted to share this file with someone outside the &lt;code>groupname&lt;/code> group, read permissions must be added to the file for &amp;lsquo;other&amp;rsquo;:&lt;/p>
&lt;pre>&lt;code class="language-bash">username@pigeon:~$ chmod o+r myFile
&lt;/code>&lt;/pre>
&lt;p>To learn more about ownership, permissions, and groups please visit &lt;a href="../../manuals/linux_basics/permissions/">Linux Basics Permissions&lt;/a>.&lt;/p>
&lt;h2 id="set-default-permissions">Set Default Permissions&lt;/h2>
&lt;p>In Linux, it is possible to set the default file permission for new files. This is useful if you are collaborating on a project, or frequently share files and you do not want to be constantly adjusting permissions The command responsible for this is called &amp;lsquo;umask&amp;rsquo;. You should first check what your default permissions currently are by running &amp;lsquo;umask -S&amp;rsquo;.&lt;/p>
&lt;pre>&lt;code class="language-bash">username@pigeon:~$ umask -S
u=rwx,g=rx,o=rx
&lt;/code>&lt;/pre>
&lt;p>To set your default permissions, simply run umask with the correct options. Please note, that this does not change permissions on any existing files, only new files created after you update the default permissions. For instance, if you wanted to set your default permissions to you having full control, your group being able to read and execute your files, and no one else to have access, you would run:&lt;/p>
&lt;pre>&lt;code class="language-bash">username@pigeon:~$ umask u=rwx,g=rx,o=
&lt;/code>&lt;/pre>
&lt;p>It is also important to note that these settings only affect your current session.
If you log out and log back in, these settings will be reset.
To make your changes permanent you need to add them to your &lt;code>.bashrc&lt;/code> file, which is a hidden file in your home directory (if you do not have a &lt;code>.bashrc&lt;/code> file, you will need to create an empty file called &lt;code>.bashrc&lt;/code> in your home directory).
Adding umask to your &lt;code>.bashrc&lt;/code> file is as simple as adding your umask command (such as &lt;code>umask u=rwx,g=rx,o=r&lt;/code>) to the end of the file.
Then simply log out and back in for the changes to take affect. You can double check that the settings have taken affect by running &lt;code>umask -S&lt;/code>.&lt;/p>
&lt;p>To learn more about umask please visit &lt;a href="http://www.cyberciti.biz/tips/understanding-linux-unix-umask-value-usage.html">What is Umask and How To Setup Default umask Under Linux?&lt;/a>.&lt;/p>
&lt;h2 id="file-transfers">File Transfers&lt;/h2>
&lt;p>For file transfers and data sharing, both command-line and GUI applications can
be used. For beginners we recommend the &lt;a href="https://filezilla-project.org/">FileZilla&lt;/a> GUI application
(download/install from &lt;a href="https://filezilla-project.org/">here&lt;/a>) since it is available for most OSs. A basic user
manual for FileZilla is &lt;a href="https://wiki.filezilla-project.org/FileZilla_Client_Tutorial_(en)">here&lt;/a> and a video tutorial is &lt;a href="https://www.youtube.com/watch?v=O3DudpEMPiY">here&lt;/a>.
Alternative user-friendly SCP/SFTP GUI applications include &lt;a href="https://cyberduck.io/">Cyberduck&lt;/a> and &lt;a href="https://winscp.net/eng/download.php">WinSCP&lt;/a> for Mac
and Windows OSs, respectively.&lt;/p>
&lt;h3 id="filezilla-usage">FileZilla Usage&lt;/h3>
&lt;p>When using &lt;code>FileZilla&lt;/code> a new site can be created by selecting &lt;code>File&lt;/code> &lt;strong>-&amp;gt;&lt;/strong> &lt;code>Site Manager&lt;/code>.
In the subsequent window, &lt;code>New Site&lt;/code> should be selected. Next the following information should be provided
in the right pane of the &lt;code>General&lt;/code> tab.&lt;/p>
&lt;pre>&lt;code>Protocol: SFTP
Host: cluster.hpcc.ucr.edu
Logon Type: Interactive
User: &amp;lt;username&amp;gt;
&lt;/code>&lt;/pre>
&lt;p>Under &lt;code>&amp;lt;username&amp;gt;&lt;/code> the actual username of an HPCC account should be provided. The &lt;code>Logon Type&lt;/code> can be
&lt;code>Interactive&lt;/code> or &lt;code>Key File&lt;/code> for &lt;a href="#passwordduo">Password+DUO&lt;/a> or &lt;a href="#ssh-keys">SSH Keys&lt;/a> authentication,
respectively. When choosing &lt;code>Password+DUO&lt;/code> authentication, the max connections should be configured.
To do so, navigate to the &lt;code>Transfer Settings&lt;/code> tab and make the following settings.&lt;/p>
&lt;pre>&lt;code> Limit Number of simultaneous connections: checked
Maximum number of connections: 1
&lt;/code>&lt;/pre>
&lt;p>By clicking &amp;ldquo;OK&amp;rdquo; the new site will be saved. Subsequently, one can select the new site from the main window by
clicking the arrow next to the site list, or just reopen the Site Manager and clicking the &amp;ldquo;connect&amp;rdquo;
button from the new site window.&lt;/p>
&lt;p>For ssh key based access, users want to make the selections shown in the Figure below. For this
access method it is important to choose the &lt;code>Site Manager&lt;/code> option as FileZilla&amp;rsquo;s Quick Access method
will not work here.&lt;/p>
&lt;center>&lt;img title="FileZilla_ssh_key" src="https://girke.bioinformatics.ucr.edu/GEN242/tutorials/linux/images/FileZilla_ssh_key.png" width="600">&lt;img/>&lt;/center>
&lt;center>FileZilla settings with an SSH key. For generating SSH keys see &lt;a href="https://hpcc.ucr.edu/manuals/login/#ssh-keys">here&lt;/a>.&lt;/center>
&lt;p>&lt;br>&lt;/br>&lt;/p>
&lt;h2 id="command-line-scp">Command-line SCP&lt;/h2>
&lt;p>Advantages of this method include: batch up/downloads and ease of automation. A detailed manual is available &lt;a href="https://linux.die.net/man/1/scp">here&lt;/a>.&lt;/p>
&lt;ul>
&lt;li>
&lt;p>To copy files To the server run the following on your workstation or laptop:&lt;/p>
&lt;p>&lt;code>scp -r &amp;lt;path_to_directory&amp;gt; &amp;lt;your_username&amp;gt;@&amp;lt;host_name&amp;gt;:&lt;/code>&lt;/p>
&lt;/li>
&lt;li>
&lt;p>To copy files From the server run the following on your workstation or laptop:&lt;/p>
&lt;p>&lt;code>scp -r &amp;lt;your_username&amp;gt;@&amp;lt;host_name&amp;gt;:&amp;lt;path_to_directory&amp;gt; .&lt;/code>&lt;/p>
&lt;/li>
&lt;/ul>
&lt;h2 id="copying-bigdata">Copying bigdata&lt;/h2>
&lt;p>Rsync can:&lt;/p>
&lt;ul>
&lt;li>Copy (transfer) directories between different locations&lt;/li>
&lt;li>Perform transfers over the network via SSH&lt;/li>
&lt;li>Compare large data sets (&lt;code>-n, --dry-run&lt;/code> option)&lt;/li>
&lt;li>Resume interrupted transfers&lt;/li>
&lt;/ul>
&lt;p>Rsync Notes:&lt;/p>
&lt;ul>
&lt;li>Rsync can be used on Windows, but you must install &lt;a href="https://cygwin.com">Cygwin&lt;/a>. Most Mac and Linux systems already have rsync install by default.&lt;/li>
&lt;li>Always put the / after both folder names, e.g: &lt;code>FOLDER_A/&lt;/code> Failing to do so will result in the nesting folders every time you try to resume. If you don&amp;rsquo;t put / you will get a second folder_B inside folder_B &lt;code>FOLDER_A/FOLDER_A/&lt;/code>&lt;/li>
&lt;li>Rsync only copies by default.&lt;/li>
&lt;li>Once the rsync command is done, run it again. The second run will be shorter and can be used as a double check. If there was no output from the second run then nothing changed.&lt;/li>
&lt;li>To learn more try &lt;code>man rsync&lt;/code>&lt;/li>
&lt;/ul>
&lt;p>If you are transfering to, or from, your laptop/workstation it is required that you run the rsync command locally from your laptop/workstation.&lt;/p>
&lt;p>To transfer to the cluster:&lt;/p>
&lt;pre>&lt;code class="language-bash">rsync -av --progress FOLDER_A/ cluster.hpcc.ucr.edu:FOLDER_A/
&lt;/code>&lt;/pre>
&lt;p>To transfer from the cluster:&lt;/p>
&lt;pre>&lt;code class="language-bash">rsync -av --progress cluster.hpcc.ucr.edu:FOLDER_A/ FOLDER_A/
&lt;/code>&lt;/pre>
&lt;p>Rsync will use SSH and will ask you for your cluster password, the same way SSH or SCP does.&lt;/p>
&lt;p>If your rsync transer was interrupted, rsync can continue where it left off. Simply run the same command again to resume.&lt;/p>
&lt;h2 id="copying-large-folders-on-the-cluster-between-directories">Copying large folders on the cluster between Directories&lt;/h2>
&lt;p>If you want to syncronize the contents from one directory to another, then use the following:&lt;/p>
&lt;pre>&lt;code class="language-bash">rsync -av --progress PATH_A/FOLDER_A/ PATH_B/FOLDER_A/
&lt;/code>&lt;/pre>
&lt;p>Rsync does not move but only copies. Thus you would need to delete the original once you confirm that everything has been transfered.&lt;/p>
&lt;h2 id="copying-large-folders-between-the-cluster-and-other-servers">Copying large folders between the cluster and other servers&lt;/h2>
&lt;p>If you want to copy data from the cluster to your own server, or another remote system, use the following:&lt;/p>
&lt;pre>&lt;code class="language-bash">rsync -ai FOLDER_A/ sever2.xyz.edu:FOLDER_A/
&lt;/code>&lt;/pre>
&lt;p>The sever2.xyz.edu machine must be a server that accepts Rsync connections via SSH.&lt;/p>
&lt;h2 id="sharing-files-on-the-web">Sharing Files on the Web&lt;/h2>
&lt;p>Simply create a symbolic link or move the files into your html directory when you want to share them.
For exmaple, log into the HPC cluster and run the following:&lt;/p>
&lt;pre>&lt;code class="language-bash"># Make sure you have an html directory
mkdir ~/.html
#Make sure permissions are set correctly
chmod a+x ~/
chmod a+rx ~/.html
# Make a new web project directory
mkdir www-project
chmod a+rx www-project
# Create a default test file
echo '&amp;lt;h1&amp;gt;Hello!&amp;lt;/h1&amp;gt;' &amp;gt; ~/www-project/index.html
# Create shortcut/link for new web project in html directory
ln -s ~/www-project ~/.html/
&lt;/code>&lt;/pre>
&lt;p>Now, test it out by pointing your web-browser to &lt;a href="https://cluster.hpcc.ucr.edu/~username/www-project/">https://cluster.hpcc.ucr.edu/~username/www-project/&lt;/a>
Be sure to replace &lt;code>username&lt;/code> with your actual user name.&lt;/p>
&lt;h2 id="password-protect-web-pages">Password Protect Web Pages&lt;/h2>
&lt;p>Files in web directories can be password protected.
First create a password file and then create a new user:&lt;/p>
&lt;pre>&lt;code class="language-bash">touch ~/.html/.htpasswd
htpasswd ~/.html/.htpasswd newwebuser
&lt;/code>&lt;/pre>
&lt;p>This will prompt you to enter a password for the new user &amp;lsquo;newwebuser&amp;rsquo;.
Create a new directory, or go to an existing directory, that you want to password protect:&lt;/p>
&lt;pre>&lt;code class="language-bash">mkdir ~/.html/locked_dir
cd ~/.html/locked_dir
&lt;/code>&lt;/pre>
&lt;p>For the above commands you can choose any directory name you want.&lt;/p>
&lt;p>Then place the following content within a file called &lt;code>.htaccess&lt;/code>:&lt;/p>
&lt;pre>&lt;code class="language-apache">AuthName 'Please login'
AuthType Basic
AuthUserFile /rhome/username/.html/.htpasswd
require user newwebuser
&lt;/code>&lt;/pre>
&lt;p>Now, test it out by pointing your web-browser to &lt;a href="http://cluster.hpcc.ucr.edu/~username/locked_dir">http://cluster.hpcc.ucr.edu/~username/locked_dir&lt;/a>
Be sure to replace &lt;code>username&lt;/code> with your actual user name for the above code and URL.&lt;/p>
&lt;h2 id="google-drive">Google Drive&lt;/h2>
&lt;p>There are several tools used to transfer files from Google Drive to the cluster, however RClone may be the easiest to setup.&lt;/p>
&lt;ol>
&lt;li>
&lt;p>Create an &lt;code>SSH&lt;/code> tunnel to the cluster, (MS Windows users should use &lt;code>MobaXterm&lt;/code>):&lt;/p>
&lt;pre>&lt;code>ssh -L 53682:localhost:53682 username@cluster.hpcc.ucr.edu
&lt;/code>&lt;/pre>
&lt;/li>
&lt;li>
&lt;p>Once you have logged into the cluster with the above command, then load &lt;code>rclone&lt;/code> via the module system and run it, like so:&lt;/p>
&lt;pre>&lt;code>module load rclone
rclone config
&lt;/code>&lt;/pre>
&lt;/li>
&lt;li>
&lt;p>After that, follow this &lt;a href="https://rclone.org/drive/">RClone Walkthrough&lt;/a> to complete your setup.&lt;/p>
&lt;/li>
&lt;/ol></description></item><item><title>Manuals: Security</title><link>https://hpcc.ucr.edu/manuals/hpc_cluster/security/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://hpcc.ucr.edu/manuals/hpc_cluster/security/</guid><description>
&lt;h2 id="protection-levels-and-classification">Protection Levels and Classification&lt;/h2>
&lt;p>UCR protection levels, and data classifications are outlined by UCOP as a UC wide policy: &lt;a href="https://security.ucop.edu/policies/institutional-information-and-it-resource-classification.html">UCOP Institutional Information and IT Resource Classification&lt;/a>
According to the above documentation, there are 4 levels of protection for 4 classifications of data:&lt;/p>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th>Protection Level&lt;/th>
&lt;th>Policy&lt;/th>
&lt;th>Examples&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>P1 - Minimal&lt;/td>
&lt;td>IS-1&lt;/td>
&lt;td>Internet facing websites, press releases, anything intended for public use&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>P2 - Low&lt;/td>
&lt;td>IS-2&lt;/td>
&lt;td>Unpublished research work, intellectual property NOT classified as P3 or P4&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>P3 - Moderate&lt;/td>
&lt;td>IS-3&lt;/td>
&lt;td>Research information classified by an Institutional Review Board as P3 (ie. dbGaP from NIH)&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>P4 - High&lt;/td>
&lt;td>IS-4&lt;/td>
&lt;td>Protected Health Information (PHI/HIPAA), patient records, sensitive identifiable human subject research data, Social Security Numbers&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;p>The HPC cluster could be compliant with with other security polices (ie. NIH), however the policy must be reviewed by our security team.&lt;/p>
&lt;p>At this time the HPC cluster is not a IS-4 (P4) compliant cluster. If you have needs for very sensitive data, it may be best to work with UCSD and their &lt;a href="https://sherlock.sdsc.edu/">Sherlock service&lt;/a>.
Our cluster is IS-3 compliant, however there are several responsibilities that users will need to adhere to.&lt;/p>
&lt;h2 id="general-guidelines">General Guidelines&lt;/h2>
&lt;p>&lt;span style="color:red">First, please contact us (&lt;a href="mailto:support@hpcc.ucr.edu">support@hpcc.ucr.edu&lt;/a>) before transferring any data to the cluster.
After we have reviewed your needs, data classification and appropriate protection level, then it may be possible to proceed to use the HPCC.&lt;/span>&lt;/p>
&lt;p>Here are a few basic rules to keep in mind:&lt;/p>
&lt;ul>
&lt;li>Always be aware of access control methods (Unix permissions and ACLs), do not allow others to view the data (ie. chmod 400 filename)&lt;/li>
&lt;li>Do not make unnecessary copies of the data&lt;/li>
&lt;li>Do not transfer the data to insecure locations&lt;/li>
&lt;li>Encrypt data when/where possible&lt;/li>
&lt;li>Delete all data when it is no longer needed&lt;/li>
&lt;/ul>
&lt;h2 id="access-controls">Access Controls&lt;/h2>
&lt;p>When sharing files with others, it is imperative that proper permission are used.
However, basic Unix permissions (user,group,other) may not be adequate.
It is better to use ACLs in order to allow fine grained access to sensitive files.&lt;/p>
&lt;h3 id="gpfs-acls">GPFS ACLs&lt;/h3>
&lt;p>GPFS is used for most of our filesystems (/rhome and /bigdata) and it uses nfsv4 style ACLs.
Users are able to explicitly allow many individuals, or groups, access to specific files or directories.&lt;/p>
&lt;pre>&lt;code class="language-bash"># Get current permissions and store in acls file
mmgetacl /path/to/file &amp;gt; ~/acls.txt
# Edit acls file containing permissions
vim ~/acls.txt
# Apply new permissions to file
mmputacl -i ~/acls.txt /path/to/file
# Delete acls file
rm ~/acls.txt
&lt;/code>&lt;/pre>
&lt;p>For more information regarding GPFS ACLs refer to the following: &lt;a href="https://www.ibm.com/support/knowledgecenter/en/STXKQY_4.2.3/com.ibm.spectrum.scale.v4r23.doc/bl1adm_nfsv4syn.htm">GPFS ACLs&lt;/a>&lt;/p>
&lt;h3 id="xfs-acls">XFS ACLs&lt;/h3>
&lt;p>The XFS filesystem is used for the CentOS operating system and typical unix locations (/,/var,/tmp,etc), as well as /secure.
For more information on how to use ACLs under XFS, please refer to the following: &lt;a href="https://vishmule.com/2015/06/11/access-control-list-acl-permissions-in-rhel7centos7/">CentOS 7 XFS&lt;/a>&lt;/p>
&lt;blockquote>
&lt;p>Note: ACLs are not applicable to gocryptfs, which is a FUSE filesystem, not GPFS nor XFS.&lt;/p>
&lt;/blockquote>
&lt;h2 id="encryption">Encryption&lt;/h2>
&lt;p>Under the IS-3 policy, P3 data encryption is mandatory.
It is best if you get into the habit of doing encryption in transit, as well as encryption at rest.
This means, when you move the data (transit) or when the data is not in use (rest), it should be encrypted.&lt;/p>
&lt;h3 id="in-transit">In Transit&lt;/h3>
&lt;p>When transferring files make sure that files are encrypted in flight with one of the following transfer protocols:&lt;/p>
&lt;ul>
&lt;li>SCP&lt;/li>
&lt;li>SFTP&lt;/li>
&lt;li>RSYNC (via SSH)&lt;/li>
&lt;/ul>
&lt;p>The destination for sensitive data on the cluster must also be encrypted at rest under one of the follow secure locations:&lt;/p>
&lt;ul>
&lt;li>/dev/shm/ - This location is in RAM, so it does not exist at rest (ensure proper ACLs)&lt;/li>
&lt;li>/secure - This location is encrypted at rest with AES 256 key length (ensure proper ACLs)&lt;/li>
&lt;li>/run/user/$EUID/unencrypted - This location is manually managed, and should be created for access to unencrypted files.&lt;/li>
&lt;/ul>
&lt;p>It is also possible to encrypt your files with GPG (&lt;a href="https://kb.iu.edu/d/awio">GPG Example&lt;/a>), before they are transferred.
Thus, during transfer they will be GPG encrypted. However, decryption must occur in one of the secure locations mentioned above.&lt;/p>
&lt;blockquote>
&lt;p>Note: Never store passphrases/passwords/masterkeys in an unsecure location (ie. a plain text script under /rhome).&lt;/p>
&lt;/blockquote>
&lt;h3 id="at-rest">At Rest&lt;/h3>
&lt;p>There are 3 methods available on the cluster for encryption at rest:&lt;/p>
&lt;ol>
&lt;li>GPG encryption of files via the command line &lt;a href="https://kb.iu.edu/d/awio">GPG Example&lt;/a>, however you must ensure proper ACLs and decryption must occur in a secure location.&lt;/li>
&lt;li>The location &amp;ldquo;/secure&amp;rdquo; is encrypted and is mounted on the head nodes, however you must ensure proper ACLs.&lt;/li>
&lt;li>Create your own location with &lt;a href="https://nuetzlich.net/gocryptfs/forward_mode_crypto/">gocryptfs&lt;/a>.&lt;/li>
&lt;/ol>
&lt;h4 id="gocryptfsmgr">GocryptfsMgr&lt;/h4>
&lt;p>You can use &lt;code>gocryptfs&lt;/code> directly or use the &lt;code>gocryptfsmgr&lt;/code>, which automates a few steps in order to simplify things.&lt;/p>
&lt;p>Here are the basics when using &lt;code>gocryptfsmgr&lt;/code>:&lt;/p>
&lt;pre>&lt;code class="language-bash"># Create new encrypted data directory
gocryptfsmgr create bigdata privatedata1
# List all encrypted and unencrypted (access point) directories
gocryptfsmgr list
# Unencrypted privatedata1 (create access point)
gocryptfsmgr open bigdata privatedata1 rw
# Transfer files (ie. SCP,SFTP,RSYNC)
scp user@remote-server:sensitive_file.txt $UNENCRYPTED/privatedata1/sensitive_file.txt
# Remove access point (re-encrypt) privatedata1
gocryptfsmgr close privatedata1
# Remove all access points (re-encrypt all)
gocryptfsmgr quit
&lt;/code>&lt;/pre>
&lt;p>For subsequent access to the encrypted space, (ie. computation or analysis) the follow procedure is recommended:&lt;/p>
&lt;pre>&lt;code class="language-bash"># Request a 2hr interactive job on an exclusive node, resources can be adjusted as needed
srun -p short --exclusive=user --pty bash -l
# Unencrypted privatedata1 in read-only mode (create access point)
gocryptfsmgr open bigdata privatedata1 ro
# Read file contents from privatedata1 (simulating work or analysis)
cat $UNENCRYPTED/privatedata1/sensitive_file.txt
# List all encrypted and unencrypted (access points) directories
gocryptfsmgr list
# Make sure we re-encrypt (close access point) for privatedata1
gocryptfsmgr close privatedata1
# Exit from interactive job
exit
&lt;/code>&lt;/pre>
&lt;p>With the above methods you can create multiple encrypted directories and access points and move between them.&lt;/p>
&lt;h4 id="gocryptfs">Gocryptfs&lt;/h4>
&lt;p>When using the &lt;code>gocryptfs&lt;/code> directly, you will need to know a bit more details on how it works.
The &lt;code>gocryptfs&lt;/code> module on the HPCC cluster uses these predefined variables:&lt;/p>
&lt;ol>
&lt;li>&lt;code>HOME_ENCRYPTED&lt;/code> = &lt;code>/rhome/$USER/encrypted&lt;/code> - Very small encrypted space, not recommended to use&lt;/li>
&lt;li>&lt;code>BIGDATA_ENCRYPTED&lt;/code> = &lt;code>/rhome/$USER/bigdata/encrypted&lt;/code> - Best encrypted space for private data sets&lt;/li>
&lt;li>&lt;code>SHARED_ENCRYPTED&lt;/code> = &lt;code>/rhome/$USER/shared/encrypted&lt;/code> - Encrypted space when intending to share data sets with group&lt;/li>
&lt;li>&lt;code>UNENCRYPTED&lt;/code> = &lt;code>/run/user/$UID/unencrypted&lt;/code> - Access directory where encrypted data will be viewed as unencrypted&lt;/li>
&lt;/ol>
&lt;p>Here is an example how to create an encrypted directory under the &lt;code>BIGDATA_ENCRYPTED&lt;/code> location using &lt;code>gocryptfs&lt;/code>:&lt;/p>
&lt;pre>&lt;code class="language-bash"># Load gocyptfs software
module load gocryptfs
# Create empty data directory
mkdir -p $BIGDATA_ENCRYPTED/privatedata1
# Then intialize empty directory and encrypt it
gocryptfs -aessiv -init $BIGDATA_ENCRYPTED/privatedata1
# Create access point directory where encrypted files will be viewed as unencrypted
mkdir -p $UNENCRYPTED/privatedata1
# After that mount the encrypted directory on the access point and open a new shell within it
gocryptfssh $BIGDATA_ENCRYPTED/privatedata1
# Transfer files (ie. SCP,SFTP,RSYNC)
scp user@remote-server:sensitive_file.txt $UNENCRYPTED/sensitive_file.txt
# Exiting this shell will automatically unmount the unencrypted directory
exit
&lt;/code>&lt;/pre>
&lt;p>For subsequent access to the encrypted space, (ie. computation or analysis) the follow procedure is recommended:&lt;/p>
&lt;pre>&lt;code class="language-bash"># Request a 2hr interactive job on an exclusive node, resources can be adjusted as needed
srun -p short --exclusive=user --pty bash -l
# Load cyptfs software
module load gocryptfs
# Create unencrypted directory
mkdir -p $UNENCRYPTED/privatedata1
# Mount encrypted filesystem as read-only and unmount idling for 1 hour
gocryptfs -ro -i 1h -sharedstorage $BIGDATA_ENCRYPTED/privatedata1 $UNENCRYPTED/privatedata1
# Read file contents (simulating work or analysis)
cat $UNENCRYPTED/privatedata1/sensitive_file.txt
# Manually close access point when analysis has completed
fusermount -u $UNENCRYPTED/privatedata1
# Delete old empty access point
rmdir $UNENCRYPTED/privatedata1
&lt;/code>&lt;/pre>
&lt;blockquote>
&lt;p>WARNING: Avoid writing to the same file at the same time from different nodes. The encrypted file system cannot handle simultaneous writes and will corrupt the file. If simultaneous jobs are necessary then using write mode from a head node and read-only mode from compute nodes may be the best solution here.
Also, be mindful of reamaining job time and make sure that you have unmounted the unencrypted directories before your job ends.&lt;/p>
&lt;/blockquote>
&lt;p>For another example on how to use gocrypfs on an HPC cluster: &lt;a href="https://hpc.uni.lu/blog/2018/sensitive-data-encryption-using-gocryptfs/">Luxembourg HPC gocryptfs Example&lt;/a>&lt;/p>
&lt;h2 id="deletion">Deletion&lt;/h2>
&lt;p>To ensure the complete removal of data, it is best to &lt;code>shred&lt;/code> files instead of removing them with &lt;code>rm&lt;/code>. The &lt;code>shred&lt;/code> program will overwrite the contents of a file with randomized data such that recovery of this file will be very difficult, if not impossible.&lt;/p>
&lt;p>Instead of using the common &lt;code>rm&lt;/code> command to delete something, please use the &lt;code>shred&lt;/code> command, like so:&lt;/p>
&lt;pre>&lt;code>shred -u somefile
&lt;/code>&lt;/pre>
&lt;p>The above command will overwrite the file with random data, and then remove (unlink) it.&lt;/p>
&lt;p>If we want to be even more secure, we can pass over the file seven times to ensure that reconstruction is nearly impossible, then remove it:&lt;/p>
&lt;pre>&lt;code>shred -v -n 6 -z -u somefile
&lt;/code>&lt;/pre></description></item><item><title>Manuals: Communicating</title><link>https://hpcc.ucr.edu/manuals/hpc_cluster/users/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://hpcc.ucr.edu/manuals/hpc_cluster/users/</guid><description>
&lt;h2 id="communicating-with-others">Communicating with others&lt;/h2>
&lt;p>The cluster is a shared resource, and communicating with other users can help to schedule large computations.&lt;/p>
&lt;p>&lt;strong>Looking-Up Specific Users&lt;/strong>&lt;/p>
&lt;p>A convenient overview of all users and their lab affiliations can be retrieved with the following command:&lt;/p>
&lt;pre>&lt;code class="language-bash">user_details.sh
&lt;/code>&lt;/pre>
&lt;p>You can search for specific users by running:&lt;/p>
&lt;pre>&lt;code class="language-bash">MATCH1='username1' # Searches by real name, and username, and email address and PI name
MATCH2='username2'
user_details.sh | grep -P &amp;quot;$MATCH1|$MATCH2&amp;quot;
&lt;/code>&lt;/pre>
&lt;p>&lt;strong>Listing Users with Active Jobs on the Cluster&lt;/strong>
To get a list of usernames:&lt;/p>
&lt;pre>&lt;code class="language-bash">squeue --format '%u' | sort | uniq
&lt;/code>&lt;/pre>
&lt;p>To get the list of real names:&lt;/p>
&lt;pre>&lt;code class="language-bash">grep &amp;lt;(user_details.sh | awk '{print $2,$3,$4}') -f &amp;lt;(squeue --format '%u' --noheader | sort | uniq) | awk '{print $1,$2}'
&lt;/code>&lt;/pre>
&lt;p>To get the list of emails:&lt;/p>
&lt;pre>&lt;code class="language-bash">grep &amp;lt;(user_details.sh | awk '{print $4,$5}') -f &amp;lt;(squeue --format '%u' --noheader | sort | uniq) | awk '{print $2}'
&lt;/code>&lt;/pre></description></item><item><title>Manuals: Terminal-based Working Environments</title><link>https://hpcc.ucr.edu/manuals/hpc_cluster/terminalide/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://hpcc.ucr.edu/manuals/hpc_cluster/terminalide/</guid><description>
&lt;h1 id="terminal-ides">Terminal IDEs&lt;/h1>
&lt;p>This page introduces several terminal-based working environments available on UCR&amp;rsquo;s
HPC cluster that are useful for a variety of computer languages.&lt;/p>
&lt;h2 id="vimnvim-basics">Vim/Nvim Basics&lt;/h2>
&lt;p>To work efficiently on remote systems like a computer cluster, it is essential
to learn how to work in a pure command-line interface. GUI environments like
RStudio and similar coding environments are not suitable for this. In addition,
there is a lot of value of knowing how to work in an environment that is not
restricted to a specific programming language. Therefore, for working on remote
systems like HPCC Cluster, this site focuses on Nvim and Tmux. Both are useful
for many programming languages. Combinded with the &lt;code>nvim-r&lt;/code> plugin they also
provide a powerful command-line working environment for R. Users of Emacs may
want to consider using &lt;a href="https://ess.r-project.org/">ESS&lt;/a> instead. The following
provides a brief introduction to the Nvim-R-Tmux environment.&lt;/p>
&lt;h3 id="vim-overview">Vim overview&lt;/h3>
&lt;p>The following opens a file (here &lt;code>myfile&lt;/code>) with nvim (or vim)&lt;/p>
&lt;pre>&lt;code class="language-sh">nvim myfile.txt # for neovim (or 'vim myfile.txt' for vim)
&lt;/code>&lt;/pre>
&lt;p>Once you are in Nvim, there are three main modes: normal, insert and command mode. The most important commands for switching between the three modes are:&lt;/p>
&lt;ul>
&lt;li>&lt;code>i&lt;/code>: The &lt;code>i&lt;/code> key brings you from the normal mode to the insert mode. The latter is used for typing.&lt;/li>
&lt;li>&lt;code>Esc&lt;/code>: The &lt;code>Esc&lt;/code> key brings you from the insert mode back to the normal mode.&lt;/li>
&lt;li>&lt;code>:&lt;/code>: The &lt;code>:&lt;/code> key starts the command mode at the bottom of the screen.&lt;/li>
&lt;/ul>
&lt;p>Use the arrow keys to move your cursor in the text. Using &lt;code>Fn Up/Down key&lt;/code> allows to page through
the text quicker. In the following command overview, all commands starting with &lt;code>:&lt;/code> need to be typed in the command mode.
All other commands are typed in the normal mode after pushing the &lt;code>Esc&lt;/code> key.&lt;/p>
&lt;p>Important modifier keys to control vim/nvim&lt;/p>
&lt;ul>
&lt;li>&lt;code>:w&lt;/code>: save changes to file. If you are in editing mode you have to hit &lt;code>Esc&lt;/code> first.&lt;/li>
&lt;li>&lt;code>:q&lt;/code>: quit file that has not been changed&lt;/li>
&lt;li>&lt;code>:wq&lt;/code>: save and quit file&lt;/li>
&lt;li>&lt;code>:!q&lt;/code>: quit file without saving any changes&lt;/li>
&lt;/ul>
&lt;h3 id="useful-resources-for-learning-vimnvim">Useful resources for learning vim/nvim&lt;/h3>
&lt;ul>
&lt;li>&lt;a href="http://www.openvim.com">Interactive Vim Tutorial&lt;/a>&lt;/li>
&lt;li>&lt;a href="http://vimdoc.sourceforge.net/">Official Vim Documentation&lt;/a>&lt;/li>
&lt;li>&lt;a href="../../manuals/linux_basics/vim/">HPCC Linux Manual&lt;/a>&lt;/li>
&lt;/ul>
&lt;h2 id="for-r-nvim-r">For R: nvim-R&lt;/h2>
&lt;h3 id="basics">Basics&lt;/h3>
&lt;p>Tmux is a terminal multiplexer that allows to split terminal windows and to detach/reattach to
existing terminal sessions. Combinded with the &lt;code>nvim-r&lt;/code> plugin it provides a powerful command-line working
environment for R where users can send code from a script to the R console or command-line.
Both tmux and the &lt;code>nvim-r&lt;/code> plugin need to be installed on a system. On HPCC Cluster both are configured
in each user account. If this is not the case then follow the quick configuration instructions given in the following subsection.&lt;/p>
&lt;center>&lt;img title="Nvim-R" src="https://raw.githubusercontent.com/jalvesaq/Nvim-R/master/Nvim-R.gif" >&lt;/center>
&lt;center>Nvim-R IDE for R&lt;/center>
&lt;h3 id="quick-configuration-in-user-accounts">Quick configuration in user accounts&lt;/h3>
&lt;p>Skip these steps if Nvim-R-Tmux is already configured in your account. Or follow the &lt;a href="https://github.com/tgirke/Nvim-R_Tmux">detailed
instructions&lt;/a> to install Nvim-R-Tmux from scratch on your own system.&lt;/p>
&lt;ol>
&lt;li>Log in to your user account on HPCC and execute &lt;code>Install_Nvim-R_Tmux&lt;/code> (old: &lt;code>install_nvimRtmux&lt;/code>). Alternatively, follow these step-by-step &lt;a href="https://github.com/tgirke/Nvim-R_Tmux">install commands&lt;/a>.&lt;/li>
&lt;li>To enable the nvim-R-tmux environment, log out and in again.&lt;/li>
&lt;li>Follow usage instructions of next section.&lt;/li>
&lt;/ol>
&lt;h3 id="basic-usage-of-nvim-r-tmux">Basic usage of Nvim-R-Tmux&lt;/h3>
&lt;p>The official and much more detailed user manual for &lt;code>Nvim-R&lt;/code> is available &lt;a href="https://github.com/jalvesaq/Nvim-R/blob/master/doc/Nvim-R.txt">here&lt;/a>.
The following gives a short introduction into the basic usage of Nvim-R-Tmux:&lt;/p>
&lt;p>&lt;strong>1. Start tmux session&lt;/strong> (optional)&lt;/p>
&lt;p>Note, running Nvim from within a tmux session is optional. Skip this step if tmux functionality is not required (&lt;em>e.g.&lt;/em> reattaching to sessions on remote systems).&lt;/p>
&lt;pre>&lt;code class="language-sh">tmux # starts a new tmux session
tmux a # attaches to an existing session
&lt;/code>&lt;/pre>
&lt;p>&lt;strong>2. Open nvim-connected R session&lt;/strong>&lt;/p>
&lt;p>Open a &lt;code>*.R&lt;/code> or &lt;code>*.Rmd&lt;/code> file with &lt;code>nvim&lt;/code> and intialize a connected R session with &lt;code>\rf&lt;/code>. This command can be remapped to other key combinations, e.g. uncommenting lines 10-12 in &lt;code>.config/nvim/init.vim&lt;/code> will remap it to the &lt;code>F2&lt;/code> key. Note, the resulting split window among Nvim and R behaves like a split viewport in &lt;code>nvim&lt;/code> or &lt;code>vim&lt;/code> meaning the usage of &lt;code>Ctrl-w w&lt;/code> followed by &lt;code>i&lt;/code> and &lt;code>Esc&lt;/code> is important for navigation.&lt;/p>
&lt;pre>&lt;code class="language-sh">nvim myscript.R # or *.Rmd file
&lt;/code>&lt;/pre>
&lt;p>&lt;strong>3. Send R code from nvim to the R pane&lt;/strong>&lt;/p>
&lt;p>Single lines of code can be sent from nvim to the R console by pressing the space bar. To send
several lines at once, one can select them in nvim&amp;rsquo;s visual mode and then hit the space bar.
Please note, the default command for sending code lines in the nvim-r-plugin is &lt;code>\l&lt;/code>. This key
binding has been remapped in the provided &lt;code>.config/nvim/init.vim&lt;/code> file to the space bar. Most other key bindings (shortcuts) still start with the &lt;code>\&lt;/code> as LocalLeader, &lt;em>e.g.&lt;/em> &lt;code>\rh&lt;/code> opens the help for a function/object where the curser is located in nvim. More details on this are given below.&lt;/p>
&lt;h3 id="important-keybindings-for-nvim">Important keybindings for nvim&lt;/h3>
&lt;p>The main advantages of Neovim compared to Vim are its better performance and its built-in terminal emulator facilitating the communication among Neovim and interactive programming environments such as R. Since the Vim and Neovim environments are managed independently, one can run them in parallel on the same system without interfering with each other. The usage of Neovim is almost identical to Vim.&lt;/p>
&lt;p>&lt;strong>Nvim commands&lt;/strong>&lt;/p>
&lt;ul>
&lt;li>&lt;code>\rf&lt;/code>: opens vim-connected R session. If you do this the first time in your user account, you might be asked to create an &lt;code>R&lt;/code> directory under &lt;code>~/&lt;/code>. If so approve this action by pressing &lt;code>y&lt;/code>.&lt;/li>
&lt;li>&lt;code>spacebar&lt;/code>: sends code from vim to R; here remapped in &lt;code>init.vim&lt;/code> from default &lt;code>\l&lt;/code>&lt;/li>
&lt;li>&lt;code>:split&lt;/code> or &lt;code>:vsplit&lt;/code>: splits viewport (similar to pane split in tmux)&lt;/li>
&lt;li>&lt;code>gz&lt;/code>: maximizes size of viewport in normal mode (similar to Tmux&amp;rsquo;s &lt;code>Ctrl-a z&lt;/code> zoom utility)&lt;/li>
&lt;li>&lt;code>Ctrl-w w&lt;/code>: jumps cursor to R viewport and back; toggle between insert (&lt;code>i&lt;/code>) and command (&lt;code>Esc&lt;/code>) mode is required for navigation and controlling the environment.&lt;/li>
&lt;li>&lt;code>Ctrl-w r&lt;/code>: swaps viewports&lt;/li>
&lt;li>&lt;code>Ctrl-w =&lt;/code>: resizes splits to equal size&lt;/li>
&lt;li>&lt;code>:resize &amp;lt;+5 or -5&amp;gt;&lt;/code>: resizes height by specified value&lt;/li>
&lt;li>&lt;code>:vertical resize &amp;lt;+5 or -5&amp;gt;&lt;/code>: resizes width by specified value&lt;/li>
&lt;li>&lt;code>Ctrl-w H&lt;/code> or &lt;code>Ctrl-w K&lt;/code>: toggles between horizontal/vertical splits&lt;/li>
&lt;li>&lt;code>Ctrl-spacebar&lt;/code>: omni completion for R objects/functions when nvim is in insert mode. Note, this has been remapped in &lt;code>init.vim&lt;/code> from difficult to type default &lt;code>Ctrl-x Ctrl-o&lt;/code>.&lt;/li>
&lt;li>&lt;code>:h nvim-R&lt;/code>: opens nvim-R&amp;rsquo;s user manual; navigation works the same as for any Vim/Nvim help document&lt;/li>
&lt;li>&lt;code>:Rhelp fct_name&lt;/code>: opens help for a function from nvim&amp;rsquo;s command mode with text completion support&lt;/li>
&lt;li>&lt;code>Ctrl-s and Ctrl-x&lt;/code>: freezes/unfreezes vim (some systems)&lt;/li>
&lt;/ul>
&lt;h3 id="important-keybindings-for-tmux">Important keybindings for tmux&lt;/h3>
&lt;p>&lt;strong>Pane-level commands&lt;/strong>&lt;/p>
&lt;ul>
&lt;li>&lt;code>Ctrl-a %&lt;/code>: splits pane vertically&lt;/li>
&lt;li>&lt;code>Ctrl-a &amp;quot;&lt;/code>: splits pane horizontally&lt;/li>
&lt;li>&lt;code>Ctrl-a o&lt;/code>: jumps cursor to next pane&lt;/li>
&lt;li>&lt;code>Ctrl-a Ctrl-o&lt;/code>: swaps panes&lt;/li>
&lt;li>&lt;code>Ctrl-a &amp;lt;space bar&amp;gt;&lt;/code>: rotates pane arrangement&lt;/li>
&lt;li>&lt;code>Ctrl-a Alt &amp;lt;left or right&amp;gt;&lt;/code>: resizes to left or right&lt;/li>
&lt;li>&lt;code>Ctrl-a Esc &amp;lt;up or down&amp;gt;&lt;/code>: resizes to left or right&lt;/li>
&lt;/ul>
&lt;p>&lt;strong>Window-level comands&lt;/strong>&lt;/p>
&lt;ul>
&lt;li>&lt;code>Ctrl-a n&lt;/code>: switches to next tmux window&lt;/li>
&lt;li>&lt;code>Ctrl-a Ctrl-a&lt;/code>: switches to previous tmux window&lt;/li>
&lt;li>&lt;code>Ctrl-a c&lt;/code>: creates a new tmux window&lt;/li>
&lt;li>&lt;code>Ctrl-a 1&lt;/code>: switches to specific tmux window selected by number&lt;/li>
&lt;/ul>
&lt;p>&lt;strong>Session-level comands&lt;/strong>&lt;/p>
&lt;ul>
&lt;li>&lt;code>Ctrl-a d&lt;/code>: detaches from current session&lt;/li>
&lt;li>&lt;code>Ctrl-a s&lt;/code>: switch between available tmux sesssions&lt;/li>
&lt;li>&lt;code>$ tmux new -s &amp;lt;name&amp;gt;&lt;/code>: starts new session with a specific name&lt;/li>
&lt;li>&lt;code>$ tmux ls&lt;/code>: lists available tmux session(s)&lt;/li>
&lt;li>&lt;code>$ tmux attach -t &amp;lt;id&amp;gt;&lt;/code>: attaches to specific tmux session&lt;/li>
&lt;li>&lt;code>$ tmux attach&lt;/code>: reattaches to session&lt;/li>
&lt;li>&lt;code>$ tmux kill-session -t &amp;lt;id&amp;gt;&lt;/code>: kills a specific tmux session&lt;/li>
&lt;li>&lt;code>Ctrl-a : kill-session&lt;/code>: kills a session from tmux command mode that can be initiated with &lt;code>Ctrl-a :&lt;/code>&lt;/li>
&lt;/ul>
&lt;h2 id="for-bash-python-and-other-languages">For Bash, Python and other languages&lt;/h2>
&lt;h3 id="basics-1">Basics&lt;/h3>
&lt;p>For languages other than R one can use the
&lt;a href="https://github.com/jalvesaq/vimcmdline">vimcmdline&lt;/a> plugin for nvim (or vim).
Supported languages include Bash, Python, Golang, Haskell, JavaScript, Julia,
Jupyter, Lisp, Macaulay2, Matlab, Prolog, Ruby, and Sage. The nvim terminal
also colorizes the output, as in the screenshot below, where different colors
are used for general output, positive and negative numbers, and the prompt
line.&lt;/p>
&lt;center>&lt;img title="vimcmdline" src="https://cloud.githubusercontent.com/assets/891655/7090493/5fba2426-df71-11e4-8eb8-f17668d9361a.png" >&lt;/center>
&lt;center>vimcmdline&lt;/center>
&lt;h3 id="install">Install&lt;/h3>
&lt;p>To install it, one needs to copy from the &lt;code>vimcmdline&lt;/code> resository the directories
&lt;code>ftplugin&lt;/code>, &lt;code>plugin&lt;/code> and &lt;code>syntax&lt;/code> and their files to &lt;code>~/.config/nvim/&lt;/code>. For
user accounts of UCRâ€™s HPCC, the above install script &lt;code>Install_Nvim-R_Tmux&lt;/code> (old: &lt;code>install_nvimRtmux&lt;/code>) includes the
install of &lt;code>vimcmdline&lt;/code> (since 09-Jun-18).&lt;/p>
&lt;h3 id="usage">Usage&lt;/h3>
&lt;p>The usage of &lt;code>vimcmdline&lt;/code> is very similar to &lt;code>nvim-R&lt;/code>. To start a connected terminal session, one
opens with nvim a code file with the extension of a given language (&lt;em>e.g.&lt;/em> &lt;code>*.sh&lt;/code> for Bash or &lt;code>*.py&lt;/code> for Python),
while the corresponding interactive interpreter session is initiated
by pressing the key sequence &lt;code>\s&lt;/code> (corresponds to &lt;code>\rf&lt;/code> under &lt;code>nvim-R&lt;/code>). Subsequently, code lines can be sent
with the space bar. More details are available &lt;a href="https://github.com/jalvesaq/vimcmdline">here&lt;/a>.&lt;/p></description></item><item><title>Manuals: Parallel Evaluations in R</title><link>https://hpcc.ucr.edu/manuals/hpc_cluster/parallelr/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://hpcc.ucr.edu/manuals/hpc_cluster/parallelr/</guid><description>
&lt;h1 id="overview">Overview&lt;/h1>
&lt;p>R provides a variety of packages for parallel computations. One of the most
comprehensive parallel computing environments for R is &lt;a href="https://mllg.github.io/batchtools/articles/batchtools.html">&lt;code>batchtools&lt;/code>&lt;/a>
(formerly &lt;code>BatchJobs&lt;/code>). It supports both multi-core and multi-node computations with and
without schedulers. By making use of cluster template files, most schedulers
and queueing systems are also supported (e.g. Torque, Sun Grid Engine, Slurm).&lt;/p>
&lt;h2 id="r-code-of-this-section">R code of this section&lt;/h2>
&lt;p>To simplify the evaluation of the R code of this page, the corresponding text version
is available for download from &lt;a href="https://bit.ly/3m5QmMU">here&lt;/a>.&lt;/p>
&lt;h2 id="parallelization-with-batchtools">Parallelization with batchtools&lt;/h2>
&lt;p>The following introduces the usage of &lt;code>batchtools&lt;/code> for a computer cluster using SLURM as scheduler (workload manager).&lt;/p>
&lt;h2 id="set-up-working-directory-for-slurm">Set up working directory for SLURM&lt;/h2>
&lt;p>First login to your cluster account, open R and execute the following lines. This will
create a test directory (here &lt;code>mytestdir&lt;/code>), redirect R into this directory and then download
the required files:&lt;/p>
&lt;ul>
&lt;li>&lt;a href="https://bit.ly/3Oh9dRO">&lt;code>slurm.tmpl&lt;/code>&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://bit.ly/3KPBwou">&lt;code>.batchtools.conf.R&lt;/code>&lt;/a>&lt;/li>
&lt;/ul>
&lt;pre>&lt;code class="language-r">dir.create(&amp;quot;mytestdir&amp;quot;)
setwd(&amp;quot;mytestdir&amp;quot;)
download.file(&amp;quot;https://bit.ly/3Oh9dRO&amp;quot;, &amp;quot;slurm.tmpl&amp;quot;)
download.file(&amp;quot;https://bit.ly/3KPBwou&amp;quot;, &amp;quot;.batchtools.conf.R&amp;quot;)
&lt;/code>&lt;/pre>
&lt;h2 id="load-package-and-define-some-custom-function">Load package and define some custom function&lt;/h2>
&lt;p>This is the test function (here toy example) that will be run on the cluster for demonstration
purposes. It subsets the &lt;code>iris&lt;/code> data frame by rows, and appends the host name and R version of each
node where the function was executed. The R version to be used on each node can be
specified in the &lt;code>slurm.tmpl&lt;/code> file (under &lt;code>module load&lt;/code>).&lt;/p>
&lt;pre>&lt;code class="language-r">library('RenvModule')
module('load','slurm') # Loads slurm among other modules
library(batchtools)
myFct &amp;lt;- function(x) {
result &amp;lt;- cbind(iris[x, 1:4,],
Node=system(&amp;quot;hostname&amp;quot;, intern=TRUE),
Rversion=paste(R.Version()[6:7], collapse=&amp;quot;.&amp;quot;))
}
&lt;/code>&lt;/pre>
&lt;h2 id="submit-jobs-from-r-to-cluster">Submit jobs from R to cluster&lt;/h2>
&lt;p>The following creates a &lt;code>batchtools&lt;/code> registry, defines the number of jobs and resource requests, and then submits the jobs to the cluster
via SLURM.&lt;/p>
&lt;pre>&lt;code class="language-r">reg &amp;lt;- makeRegistry(file.dir=&amp;quot;myregdir&amp;quot;, conf.file=&amp;quot;.batchtools.conf.R&amp;quot;)
Njobs &amp;lt;- 1:4 # Define number of jobs (here 4)
ids &amp;lt;- batchMap(fun=myFct, x=Njobs)
done &amp;lt;- submitJobs(ids, reg=reg, resources=list(partition=&amp;quot;short&amp;quot;, walltime=60, ntasks=1, ncpus=1, memory=1024))
waitForJobs() # Wait until jobs are completed
&lt;/code>&lt;/pre>
&lt;h2 id="summarize-job-status">Summarize job status&lt;/h2>
&lt;p>After the jobs are completed one instect their status as follows.&lt;/p>
&lt;pre>&lt;code class="language-r">getStatus() # Summarize job status
showLog(Njobs[1])
# killJobs(Njobs) # # Possible from within R or outside with scancel
&lt;/code>&lt;/pre>
&lt;h2 id="accessassemble-results">Access/assemble results&lt;/h2>
&lt;p>The results are stored as &lt;code>.rds&lt;/code> files in the registry directory (here &lt;code>myregdir&lt;/code>). One
can access them manually via &lt;code>readRDS&lt;/code> or use various convenience utilities provided
by the &lt;code>batchtools&lt;/code> package.&lt;/p>
&lt;pre>&lt;code class="language-r">readRDS(&amp;quot;myregdir/results/1.rds&amp;quot;) # reads from rds file first result chunk
loadResult(1)
lapply(Njobs, loadResult)
reduceResults(rbind) # Assemble result chunks in single data.frame
do.call(&amp;quot;rbind&amp;quot;, lapply(Njobs, loadResult))
&lt;/code>&lt;/pre>
&lt;h2 id="remove-registry-directory-from-file-system">Remove registry directory from file system&lt;/h2>
&lt;p>By default existing registries will not be overwritten. If required one can exlicitly
clean and delete them with the following functions.&lt;/p>
&lt;pre>&lt;code class="language-r">clearRegistry() # Clear registry in R session
removeRegistry(wait=0, reg=reg) # Delete registry directory
# unlink(&amp;quot;myregdir&amp;quot;, recursive=TRUE) # Same as previous line
&lt;/code>&lt;/pre>
&lt;h2 id="load-registry-into-r">Load registry into R&lt;/h2>
&lt;p>Loading a registry can be useful when accessing the results at a later state or
after moving them to a local system.&lt;/p>
&lt;pre>&lt;code class="language-r">from_file &amp;lt;- loadRegistry(&amp;quot;myregdir&amp;quot;, conf.file=&amp;quot;.batchtools.conf.R&amp;quot;)
reduceResults(rbind)
&lt;/code>&lt;/pre></description></item><item><title>Manuals: SSH Keys</title><link>https://hpcc.ucr.edu/manuals/hpc_cluster/sshkeys/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://hpcc.ucr.edu/manuals/hpc_cluster/sshkeys/</guid><description>
&lt;blockquote>
&lt;p>The below links to detailed instructions. A shorter but more comprehensive summary for all three OSs is available &lt;a href="https://hpcc.ucr.edu/manuals/login/#ssh-keys">here&lt;/a>.&lt;/p>
&lt;/blockquote></description></item><item><title>Manuals: Visualization</title><link>https://hpcc.ucr.edu/manuals/hpc_cluster/visual/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://hpcc.ucr.edu/manuals/hpc_cluster/visual/</guid><description>
&lt;h2 id="compute-node">Compute Node&lt;/h2>
&lt;p>We support running graphical programs on the cluster using &lt;code>VNC&lt;/code>. For more information refer to &lt;a href="../../manuals/hpc_cluster/jobs/#desktop-environments">Desktop Environments&lt;/a>.&lt;/p>
&lt;h2 id="gpu-workstation">GPU Workstation&lt;/h2>
&lt;p>If a remote compute node does not fit your needs then we also have a GPU workstation specifically designed for rendering high resolution 3D graphics.&lt;/p>
&lt;h3 id="hardware">Hardware&lt;/h3>
&lt;ul>
&lt;li>Intel(R) Xeon(R) CPU E5-2620 v4 @ 2.10GHz&lt;/li>
&lt;li>DDR4 256GB @ 2400 MHz&lt;/li>
&lt;li>NVIDIA Corporation GM204GL [Quadro M5000]&lt;/li>
&lt;li>1TB RAID 1 HDD&lt;/li>
&lt;/ul>
&lt;h3 id="software">Software&lt;/h3>
&lt;p>The GPU workstation is uniquely configured to be an extension of the HPCC cluster. Thus, all software available to the cluster is also available on the GPU workstation through &lt;a href="../../about/software/modules/">Environment Modules&lt;/a>.&lt;/p>
&lt;h3 id="access">Access&lt;/h3>
&lt;p>The GPU workstation is currently located in the Genomics building room 1208. Please check ahead of time to make sure the machine is available &lt;a href="mailto:support@hpcc.ucr.edu">support@hpcc.ucr.edu&lt;/a>.
Once you have access to the GPU workstation, login with your cluster credentials. If your username does not appear in the list, you may need to click &lt;code>Not listed?&lt;/code> at the bottom of the screen so that you are able to type in your username.&lt;/p>
&lt;h4 id="usage">Usage&lt;/h4>
&lt;p>There are 2 ways to use the GPU workstation:&lt;/p>
&lt;ol>
&lt;li>Local - Run processes directly on the GPU workstation hardware&lt;/li>
&lt;li>Remote - Run processes remotely on the GPU cluster hardware&lt;/li>
&lt;/ol>
&lt;p>&lt;strong>Local&lt;/strong>&lt;/p>
&lt;p>Local usage is very simple. Open a terminal and use the &lt;a href="../../manuals/hpc_cluster/start/#modules">Environment Modules&lt;/a> to load the desired software, then run your software from the terminal.
For example:&lt;/p>
&lt;pre>&lt;code class="language-bash">module load amira
Amira
&lt;/code>&lt;/pre>
&lt;p>&lt;strong>Remotely&lt;/strong>&lt;/p>
&lt;p>Open a terminal and submit a job. This is to reserve the time on the remote GPU node. Then once your job has started connect to the remote GPU node via ssh and forward the graphics back to the GPU workstation.
For example:&lt;/p>
&lt;ol>
&lt;li>
&lt;p>Submit a job for March 28th, 2018 at 9:30am for a duration of 24 hours, 4 cpus, 100GB memory:&lt;/p>
&lt;pre>&lt;code class="language-bash">sbatch --begin=2018-03-28T09:30:00 --time=24:00:00 -p gpu --gres=gpu:1 --mem=100g --cpus-per-task=4 --wrap='echo ${CUDA_VISIBLE_DEVICES} &amp;gt; ~/.CUDA_VISIBLE_DEVICES; sleep infinity'
&lt;/code>&lt;/pre>
&lt;p>Read about &lt;a href="../../manuals/hpc_cluster/jobs/#gpu-jobs">GPU jobs&lt;/a> for more information regarding the above.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Run the VirtualGL client in order to receive 3D graphics from the remove GPU node:&lt;/p>
&lt;pre>&lt;code class="language-bash">vglclient &amp;amp;
&lt;/code>&lt;/pre>
&lt;/li>
&lt;li>
&lt;p>Wait for the job to start, and then check where your job is running:&lt;/p>
&lt;pre>&lt;code class="language-bash">GPU_NODE=$(squeue -h -p gpu -u $USER -o '%N'); echo $GPU_NODE
&lt;/code>&lt;/pre>
&lt;/li>
&lt;li>
&lt;p>The above command should result in a GPU node name, which you then need to SSH directly into with the following:&lt;/p>
&lt;pre>&lt;code class="language-bash">ssh -XY $GPU_NODE
&lt;/code>&lt;/pre>
&lt;/li>
&lt;li>
&lt;p>Once you have SSH&amp;rsquo;ed into the remote GPU node, run setup the environment and run your software:&lt;/p>
&lt;pre>&lt;code class="language-bash">export NO_AT_BRIDGE=1
module load amira
vglrun -display :$(head -1 ~/.CUDA_VISIBLE_DEVICES) Amira
&lt;/code>&lt;/pre>
&lt;/li>
&lt;/ol></description></item><item><title>Manuals: Singularity Jobs</title><link>https://hpcc.ucr.edu/manuals/hpc_cluster/singularity/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://hpcc.ucr.edu/manuals/hpc_cluster/singularity/</guid><description>
&lt;h2 id="what-is-singularity">What is Singularity&lt;/h2>
&lt;p>In short, &lt;code>Singularity&lt;/code> is a program that will allow a user to run code or command, within a customized environment.
We will refer to this customized environment as a &lt;code>container&lt;/code>.
This type of container system is common, the more popular one being &lt;a href="https://www.docker.com/">Docker&lt;/a>.
Since &lt;code>Docker&lt;/code> requires root access and HPC users are not typically granted these permissions, we use Singularity instead.
&lt;code>Docker&lt;/code> containers can be used via &lt;code>Singularity&lt;/code>, with varying compatibility.&lt;/p>
&lt;p>&lt;code>Singularity&lt;/code> is forking into 2 branches:&lt;/p>
&lt;ul>
&lt;li>&lt;a href="https://sylabs.io/">Singularity-CE&lt;/a> - Community Edition from Sylabs.io&lt;/li>
&lt;li>&lt;a href="https://apptainer.org/">Apptainer&lt;/a> - Original Sinularity open source project&lt;/li>
&lt;/ul>
&lt;p>We will be using &lt;code>Apptainer&lt;/code> when it is ready for production use.
However, in the meantime, &lt;code>singularity-ce&lt;/code> is currently availble on the cluster.&lt;/p>
&lt;h2 id="limitations">Limitations&lt;/h2>
&lt;p>Currently we are not supporting Slurm jobs bening submitted from within a container.
If you load the container &lt;code>centos/7.9&lt;/code> and try to submit a job from within it will fail.
Please contact support in order to work around this issue.&lt;/p>
&lt;h2 id="how-to-use-singularity">How to use Singularity&lt;/h2>
&lt;p>&lt;code>Singularity&lt;/code> is easy to use.
You can run &lt;code>singularity&lt;/code> in an interactive mode by calling a shell, or you can run &lt;code>singularity&lt;/code> in a non-interactive mode and just pass it a script.
This 2 modes are very similar to job submission on the cluster; &lt;code>srun&lt;/code> is used for interactive, while &lt;code>sbatch&lt;/code> is used for non-interactive.&lt;/p>
&lt;h3 id="interactive-singularity">Interactive Singularity&lt;/h3>
&lt;p>When running singularity you need to provide the path to a &lt;code>singularity&lt;/code> image file.
For example, this would be the most basic way to get a shell within your container:&lt;/p>
&lt;pre>&lt;code class="language-bash">module load singularity
singularity shell /path/to/singularity/image
&lt;/code>&lt;/pre>
&lt;p>Typically when we install &lt;code>singularity&lt;/code> enabled software, we will also create an environment variable which holds the location of the &lt;code>singularity&lt;/code> image file.
For example, this would be how we would use the &lt;code>centos&lt;/code> module:&lt;/p>
&lt;pre>&lt;code class="language-bash">module load centos
singularity shell $CENTOS7_SING
&lt;/code>&lt;/pre>
&lt;p>There is a special shortcut for the &lt;code>centos&lt;/code> module that allows us to run the above more simply, as:&lt;/p>
&lt;pre>&lt;code class="language-bash">module load centos
centos.sh
&lt;/code>&lt;/pre>
&lt;p>Here is a another example that utilizes an interactive job:&lt;/p>
&lt;pre>&lt;code>module load centos
srun -p batch --mem=1g -c 4 --time=2:00:00 --pty centos.sh
&lt;/code>&lt;/pre>
&lt;h3 id="non-interactive-singularity">Non-Interactive Singularity&lt;/h3>
&lt;p>When running singularity as non-interactive, the same basic rules apply, we need a path to our &lt;code>singularity&lt;/code> image file as well as a command.&lt;/p>
&lt;h4 id="basics">Basics&lt;/h4>
&lt;p>For example, here is the basic syntax:&lt;/p>
&lt;pre>&lt;code class="language-bash">module load singularity
singularity exec /path/to/singularity/image someCommand
&lt;/code>&lt;/pre>
&lt;p>Using &lt;code>centos&lt;/code> as an example, you can execute an abitraty command like so:&lt;/p>
&lt;pre>&lt;code class="language-bash">module load singularity
singularity exec $CENTOS7_SING cat /etc/redhat-release
&lt;/code>&lt;/pre>
&lt;h4 id="shortcuts">Shortcuts&lt;/h4>
&lt;p>Now using the &lt;code>centos&lt;/code> shortcut:&lt;/p>
&lt;pre>&lt;code class="language-bash">module load centos
centos.sh &amp;quot;cat /etc/redhat-release&amp;quot;
&lt;/code>&lt;/pre>
&lt;p>Here is a more complex example with modules:&lt;/p>
&lt;pre>&lt;code class="language-bash">module load centos
centos.sh &amp;quot;module load samtools; samtools --help&amp;quot;
&lt;/code>&lt;/pre>
&lt;h4 id="jobs">Jobs&lt;/h4>
&lt;p>Here is an example submitted as a job:&lt;/p>
&lt;pre>&lt;code class="language-bash">module load centos
sbatch -p batch --wrap=&amp;quot;centos.sh 'module load samtools; samtools --help'&amp;quot;
&lt;/code>&lt;/pre>
&lt;h4 id="variables">Variables&lt;/h4>
&lt;p>Here is an example with passing environment variables:&lt;/p>
&lt;pre>&lt;code class="language-bash">export SINGULARITYENV_SOMETHING='stuff'
centos.sh 'echo $SOMETHING'
&lt;/code>&lt;/pre>
&lt;blockquote>
&lt;p>Notice: Just add the &lt;code>SINGULARITYENV_&lt;/code> prefix to pass any varibales to the centos container.&lt;/p>
&lt;/blockquote>
&lt;h4 id="enable-gpus">Enable GPUs&lt;/h4>
&lt;p>First review how to submit a GPU job from &lt;a href="../../manuals/hpc_cluster/jobs/#gpu-jobs">here&lt;/a>.
Then request an interactive GPU job, or embed one of the following within your submission script.&lt;/p>
&lt;p>In order to enable GPUs within your container you need to add the &lt;code>--nv&lt;/code> option to the singularity command:&lt;/p>
&lt;pre>&lt;code class="language-bash">module load centos
singularity exec -nv $CENTOS7_SING cat /etc/redhat-release
&lt;/code>&lt;/pre>
&lt;p>However, when using the &lt;code>centos&lt;/code> shortcut it is easier to just set the following environment variable then run &lt;code>centos.sh&lt;/code> as usual:&lt;/p>
&lt;pre>&lt;code class="language-bash">module load centos
export SINGULARITY_NV=1
centos.sh
&lt;/code>&lt;/pre></description></item></channel></rss>